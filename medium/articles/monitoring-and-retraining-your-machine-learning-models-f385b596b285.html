<article><div class="l"><div class="gg gh gi gj gk gl gm ce gn ch l"></div><div class="l"><header class="pw-post-byline-header go gp gq gr gs gt gu gv gw gx l"><div class="o gy u"><div class="o"><div class="fj l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://felipe-p-adachi.medium.com/?source=post_page-----f385b596b285--------------------------------" rel="noopener follow"><div class="l do"><img alt="Felipe de Pontes Adachi" class="l ch fl gz ha fp" height="48" loading="lazy" src="https://miro.medium.com/fit/c/96/96/1*s3gcSe1xJQh6KqzodxLlfA.jpeg" width="48"/><div class="fk fl l gz ha fo aq"></div></div></a></div><div class="l"><div class="pw-author bm b dm dn ga"><div class="hb o hc"><div><div aria-hidden="false" class="ci"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://felipe-p-adachi.medium.com/?source=post_page-----f385b596b285--------------------------------" rel="noopener follow">Felipe de Pontes Adachi</a></div></div><div class="hd he hf hg hh d"><span><a class="bm b hi bo hj hk hl hm hn ho hp bd bz hq hr hs cd cf cg ch ci cj" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa038269245d5&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonitoring-and-retraining-your-machine-learning-models-f385b596b285&amp;user=Felipe+de+Pontes+Adachi&amp;userId=a038269245d5&amp;source=post_page-a038269245d5----f385b596b285---------------------follow_byline-----------" rel="noopener follow">Follow</a></span></div></div></div><div class="o ao ht"><p class="pw-published-date bm b bn bo cn"><span>Mar 4, 2021</span></p><div aria-hidden="true" class="hu ci"><span aria-hidden="true" class="l"><span class="bm b bn bo cn">·</span></span></div><div class="pw-reading-time bm b bn bo cn">14 min read</div></div></div></div><div class="o ao"><div class="h k hv hw hx"><div class="hy l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on twitter" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M20 5.34c-.67.41-1.4.7-2.18.87a3.45 3.45 0 0 0-5.02-.1 3.49 3.49 0 0 0-1.02 2.47c0 .28.03.54.07.8a9.91 9.91 0 0 1-7.17-3.66 3.9 3.9 0 0 0-.5 1.74 3.6 3.6 0 0 0 1.56 2.92 3.36 3.36 0 0 1-1.55-.44V10c0 1.67 1.2 3.08 2.8 3.42-.3.06-.6.1-.94.12l-.62-.06a3.5 3.5 0 0 0 3.24 2.43 7.34 7.34 0 0 1-4.36 1.49l-.81-.05a9.96 9.96 0 0 0 5.36 1.56c6.4 0 9.91-5.32 9.9-9.9v-.5c.69-.49 1.28-1.1 1.74-1.81-.63.3-1.3.48-2 .56A3.33 3.33 0 0 0 20 5.33" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="hy l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on facebook" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 12.04c0-4.3-3.47-7.79-7.75-7.79a7.77 7.77 0 0 0-5.9 12.84 7.77 7.77 0 0 0 4.69 2.63v-5.49h-1.9v-2.2h1.9v-1.62c0-1.88 1.14-2.9 2.8-2.9.8 0 1.49.06 1.69.08v1.97h-1.15c-.91 0-1.1.43-1.1 1.07v1.4h2.17l-.28 2.2h-1.88v5.52a7.77 7.77 0 0 0 6.7-7.71" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="hy l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on linkedin" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 5.39v13.22a1.14 1.14 0 0 1-1.14 1.14H5.39a1.14 1.14 0 0 1-1.14-1.14V5.39a1.14 1.14 0 0 1 1.14-1.14h13.22a1.14 1.14 0 0 1 1.14 1.14zM8.81 10.18H6.53v7.3H8.8v-7.3zM9 7.67a1.31 1.31 0 0 0-1.3-1.32h-.04a1.32 1.32 0 0 0 0 2.64A1.31 1.31 0 0 0 9 7.71v-.04zm8.46 5.37c0-2.2-1.4-3.05-2.78-3.05a2.6 2.6 0 0 0-2.3 1.18h-.07v-1h-2.14v7.3h2.28V13.6a1.51 1.51 0 0 1 1.36-1.63h.09c.72 0 1.26.45 1.26 1.6v3.91h2.28l.02-4.43z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="l fr"><div><div aria-hidden="false" class="ci"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path clip-rule="evenodd" d="M3.57 14.67c0-.57.13-1.11.38-1.6l.02-.02v-.02l.02-.02c0-.02 0-.02.02-.02.12-.26.3-.52.57-.8L7.78 9v-.02l.01-.02c.44-.41.91-.7 1.44-.85a4.87 4.87 0 0 0-1.19 2.36A5.04 5.04 0 0 0 8 11.6L6.04 13.6c-.19.19-.32.4-.38.65a2 2 0 0 0 0 .9c.08.2.2.4.38.57l1.29 1.31c.27.28.62.42 1.03.42.42 0 .78-.14 1.06-.42l1.23-1.25.79-.78 1.15-1.16c.08-.09.19-.22.28-.4.1-.2.15-.42.15-.67 0-.16-.02-.3-.06-.45l-.02-.02v-.02l-.07-.14s0-.03-.04-.06l-.06-.13-.02-.02c0-.02 0-.03-.02-.05a.6.6 0 0 0-.14-.16l-.48-.5c0-.04.02-.1.04-.15l.06-.12 1.17-1.14.09-.09.56.57c.02.04.08.1.16.18l.05.04.03.06.04.05.03.04.04.06.1.14.02.02c0 .02.01.03.03.04l.1.2v.02c.1.16.2.38.3.68a1 1 0 0 1 .04.25 3.2 3.2 0 0 1 .02 1.33 3.49 3.49 0 0 1-.95 1.87l-.66.67-.97.97-1.56 1.57a3.4 3.4 0 0 1-2.47 1.02c-.97 0-1.8-.34-2.49-1.03l-1.3-1.3a3.55 3.55 0 0 1-1-2.51v-.01h-.02v.02zm5.39-3.43c0-.19.02-.4.07-.63.13-.74.44-1.37.95-1.87l.66-.67.97-.98 1.56-1.56c.68-.69 1.5-1.03 2.47-1.03.97 0 1.8.34 2.48 1.02l1.3 1.32a3.48 3.48 0 0 1 1 2.48c0 .58-.11 1.11-.37 1.6l-.02.02v.02l-.02.04c-.14.27-.35.54-.6.8L16.23 15l-.01.02-.01.02c-.44.42-.92.7-1.43.83a4.55 4.55 0 0 0 1.23-3.52L18 10.38c.18-.21.3-.42.35-.65a2.03 2.03 0 0 0-.01-.9 1.96 1.96 0 0 0-.36-.58l-1.3-1.3a1.49 1.49 0 0 0-1.06-.42c-.42 0-.77.14-1.06.4l-1.2 1.27-.8.8-1.16 1.15c-.08.08-.18.21-.29.4a1.66 1.66 0 0 0-.08 1.12l.02.03v.02l.06.14s.01.03.05.06l.06.13.02.02.01.02.01.02c.05.08.1.13.14.16l.47.5c0 .04-.02.09-.04.15l-.06.12-1.15 1.15-.1.08-.56-.56a2.3 2.3 0 0 0-.18-.19c-.02-.01-.02-.03-.02-.04l-.02-.02a.37.37 0 0 1-.1-.12c-.03-.03-.05-.04-.05-.06l-.1-.15-.02-.02-.02-.04-.08-.17v-.02a5.1 5.1 0 0 1-.28-.69 1.03 1.03 0 0 1-.04-.26c-.06-.23-.1-.46-.1-.7v.01z" fill="#A8A8A8" fill-rule="evenodd"></path></svg></span></button></div></div></div><div class="ib o ao"><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff385b596b285&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonitoring-and-retraining-your-machine-learning-models-f385b596b285&amp;source=--------------------------bookmark_header-----------" rel="noopener follow"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="au de aw ax ay az ba hz bc id ie if ig"><svg aria-label="Add to list bookmark button" class="ic" fill="none" height="25" viewbox="0 0 25 25" width="25"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></button></a></span></div></div><div class="ck ih"><div><div aria-hidden="false" class="ci"></div></div></div></div></div><div class="ii ij ik j i d"><div class="fj l"><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff385b596b285&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonitoring-and-retraining-your-machine-learning-models-f385b596b285&amp;source=--------------------------bookmark_header-----------" rel="noopener follow"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="au de aw il ay az ba im bc id cd o ao in io ig"><svg aria-label="Add to list bookmark button" class="ic" fill="none" height="25" viewbox="0 0 25 25" width="25"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg><p class="bm b bn bo cn">Save</p></button></a></span></div><div class="ip l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on twitter" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M20 5.34c-.67.41-1.4.7-2.18.87a3.45 3.45 0 0 0-5.02-.1 3.49 3.49 0 0 0-1.02 2.47c0 .28.03.54.07.8a9.91 9.91 0 0 1-7.17-3.66 3.9 3.9 0 0 0-.5 1.74 3.6 3.6 0 0 0 1.56 2.92 3.36 3.36 0 0 1-1.55-.44V10c0 1.67 1.2 3.08 2.8 3.42-.3.06-.6.1-.94.12l-.62-.06a3.5 3.5 0 0 0 3.24 2.43 7.34 7.34 0 0 1-4.36 1.49l-.81-.05a9.96 9.96 0 0 0 5.36 1.56c6.4 0 9.91-5.32 9.9-9.9v-.5c.69-.49 1.28-1.1 1.74-1.81-.63.3-1.3.48-2 .56A3.33 3.33 0 0 0 20 5.33" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="ip l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on facebook" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 12.04c0-4.3-3.47-7.79-7.75-7.79a7.77 7.77 0 0 0-5.9 12.84 7.77 7.77 0 0 0 4.69 2.63v-5.49h-1.9v-2.2h1.9v-1.62c0-1.88 1.14-2.9 2.8-2.9.8 0 1.49.06 1.69.08v1.97h-1.15c-.91 0-1.1.43-1.1 1.07v1.4h2.17l-.28 2.2h-1.88v5.52a7.77 7.77 0 0 0 6.7-7.71" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="ip l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on linkedin" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 5.39v13.22a1.14 1.14 0 0 1-1.14 1.14H5.39a1.14 1.14 0 0 1-1.14-1.14V5.39a1.14 1.14 0 0 1 1.14-1.14h13.22a1.14 1.14 0 0 1 1.14 1.14zM8.81 10.18H6.53v7.3H8.8v-7.3zM9 7.67a1.31 1.31 0 0 0-1.3-1.32h-.04a1.32 1.32 0 0 0 0 2.64A1.31 1.31 0 0 0 9 7.71v-.04zm8.46 5.37c0-2.2-1.4-3.05-2.78-3.05a2.6 2.6 0 0 0-2.3 1.18h-.07v-1h-2.14v7.3h2.28V13.6a1.51 1.51 0 0 1 1.36-1.63h.09c.72 0 1.26.45 1.26 1.6v3.91h2.28l.02-4.43z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="l fr"><div><div aria-hidden="false" class="ci"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path clip-rule="evenodd" d="M3.57 14.67c0-.57.13-1.11.38-1.6l.02-.02v-.02l.02-.02c0-.02 0-.02.02-.02.12-.26.3-.52.57-.8L7.78 9v-.02l.01-.02c.44-.41.91-.7 1.44-.85a4.87 4.87 0 0 0-1.19 2.36A5.04 5.04 0 0 0 8 11.6L6.04 13.6c-.19.19-.32.4-.38.65a2 2 0 0 0 0 .9c.08.2.2.4.38.57l1.29 1.31c.27.28.62.42 1.03.42.42 0 .78-.14 1.06-.42l1.23-1.25.79-.78 1.15-1.16c.08-.09.19-.22.28-.4.1-.2.15-.42.15-.67 0-.16-.02-.3-.06-.45l-.02-.02v-.02l-.07-.14s0-.03-.04-.06l-.06-.13-.02-.02c0-.02 0-.03-.02-.05a.6.6 0 0 0-.14-.16l-.48-.5c0-.04.02-.1.04-.15l.06-.12 1.17-1.14.09-.09.56.57c.02.04.08.1.16.18l.05.04.03.06.04.05.03.04.04.06.1.14.02.02c0 .02.01.03.03.04l.1.2v.02c.1.16.2.38.3.68a1 1 0 0 1 .04.25 3.2 3.2 0 0 1 .02 1.33 3.49 3.49 0 0 1-.95 1.87l-.66.67-.97.97-1.56 1.57a3.4 3.4 0 0 1-2.47 1.02c-.97 0-1.8-.34-2.49-1.03l-1.3-1.3a3.55 3.55 0 0 1-1-2.51v-.01h-.02v.02zm5.39-3.43c0-.19.02-.4.07-.63.13-.74.44-1.37.95-1.87l.66-.67.97-.98 1.56-1.56c.68-.69 1.5-1.03 2.47-1.03.97 0 1.8.34 2.48 1.02l1.3 1.32a3.48 3.48 0 0 1 1 2.48c0 .58-.11 1.11-.37 1.6l-.02.02v.02l-.02.04c-.14.27-.35.54-.6.8L16.23 15l-.01.02-.01.02c-.44.42-.92.7-1.43.83a4.55 4.55 0 0 0 1.23-3.52L18 10.38c.18-.21.3-.42.35-.65a2.03 2.03 0 0 0-.01-.9 1.96 1.96 0 0 0-.36-.58l-1.3-1.3a1.49 1.49 0 0 0-1.06-.42c-.42 0-.77.14-1.06.4l-1.2 1.27-.8.8-1.16 1.15c-.08.08-.18.21-.29.4a1.66 1.66 0 0 0-.08 1.12l.02.03v.02l.06.14s.01.03.05.06l.06.13.02.02.01.02.01.02c.05.08.1.13.14.16l.47.5c0 .04-.02.09-.04.15l-.06.12-1.15 1.15-.1.08-.56-.56a2.3 2.3 0 0 0-.18-.19c-.02-.01-.02-.03-.02-.04l-.02-.02a.37.37 0 0 1-.1-.12c-.03-.03-.05-.04-.05-.06l-.1-.15-.02-.02-.02-.04-.08-.17v-.02a5.1 5.1 0 0 1-.28-.69 1.03 1.03 0 0 1-.04-.26c-.06-.23-.1-.46-.1-.7v.01z" fill="#A8A8A8" fill-rule="evenodd"></path></svg></span></button></div></div></div></div></header><span class="l"></span><section><div><div class="fo as iv iw ix iy"></div><div class="iz ja jb jc jd"><h2 aria-label="kicker paragraph" class="je jf jg bm b hi jh ji jj jk jl jm cn jn" id="0725"><a class="au cj" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">Hands-on Tutorials</a></h2><div class=""><h1 class="pw-post-title jo jp jg bm jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ga" id="0fd1">Monitoring and Retraining Your Machine Learning Models</h1></div><div class=""><h2 class="pw-subtitle-paragraph km jp jg bm b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld cn" id="db4a">With Google Data Studio, lakeFS and Great Expectations</h2></div><figure class="lf lg lh li gx lj gl gm paragraph-image"><div class="lk ll do lm ce ln" role="button" tabindex="0"><div class="gl gm le"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/0*3pMC_IN2BUNL8kJg 640w, https://miro.medium.com/max/720/0*3pMC_IN2BUNL8kJg 720w, https://miro.medium.com/max/750/0*3pMC_IN2BUNL8kJg 750w, https://miro.medium.com/max/786/0*3pMC_IN2BUNL8kJg 786w, https://miro.medium.com/max/828/0*3pMC_IN2BUNL8kJg 828w, https://miro.medium.com/max/1100/0*3pMC_IN2BUNL8kJg 1100w, https://miro.medium.com/max/1400/0*3pMC_IN2BUNL8kJg 1400w"/><img alt="" class="ce lo lp c" height="467" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="lq bl gn gl gm lr ls bm b bn bo cn">Photo by <a class="au lt" href="https://unsplash.com/@nate_dumlao?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Nathan Dumlao</a> on <a class="au lt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="d896">Like everything in life, machine learning models go stale. In a world of ever-changing, non-stationary data, everyone needs to go back to school and recycle itself once in a while, and your model is no different.</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="351a">Well, we know that retraining our model is important, but when exactly should we do it? If we do it too frequently, we’d end up wasting valuable time and effort, but to do it seldomly would surely affect our prediction’s quality. Unfortunately, there is no one-size-fits-all answer. Each case should be carefully assessed in order to determine the impact of staleness.</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="79fc">In this article, I’d like to share my approach to monitoring and retraining on a personal project: A fake news detector web application. I’m by no means an expert on the subject, so if you have any suggestions or considerations, please feel free to get in contact.</p><h2 class="mq mr jg bm ms mt mu mv mw mx my mz na md nb nc nd mh ne nf ng ml nh ni nj jm ga" id="b6b9">The Application</h2><p class="pw-post-body-paragraph lu lv jg lw b lx nk kq lz ma nl kt mc md nm mf mg mh nn mj mk ml no mn mo mp iz ga" id="ef4c">Our simple web application is basically a fake news detector: the user is able to enter a URL of a news article, and the system will output the result of its prediction: whether it’s fake or real.</p><figure class="lf lg lh li gx lj gl gm paragraph-image"><div class="lk ll do lm ce ln" role="button" tabindex="0"><div class="gl gm np"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*sKfLQlGu8SelVJazJINkxA.gif 640w, https://miro.medium.com/max/720/1*sKfLQlGu8SelVJazJINkxA.gif 720w, https://miro.medium.com/max/750/1*sKfLQlGu8SelVJazJINkxA.gif 750w, https://miro.medium.com/max/786/1*sKfLQlGu8SelVJazJINkxA.gif 786w, https://miro.medium.com/max/828/1*sKfLQlGu8SelVJazJINkxA.gif 828w, https://miro.medium.com/max/1100/1*sKfLQlGu8SelVJazJINkxA.gif 1100w, https://miro.medium.com/max/1400/1*sKfLQlGu8SelVJazJINkxA.gif 1400w"/><img alt="" class="ce lo lp c" height="172" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="lq bl gn gl gm lr ls bm b bn bo cn">Gif by author</figcaption></figure><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="3960">For every input, the system logs the prediction’s result and additional metadata in a <strong class="lw jq">BigQuery</strong> table at <strong class="lw jq">GCP</strong>. That’s the data we’ll use to monitor our model’s performance and, when needed, to retrain it.</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="3650">This article is divided into two parts: <strong class="lw jq">Monitoring</strong> and <strong class="lw jq">Retraining.</strong></p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="f62d">First, I’ll talk about how I used the prediction logs at <strong class="lw jq">BigQuery</strong> to set up a <strong class="lw jq">Google Data Studio </strong>dashboard in order to have some updated charts and indicators to assess my text classification model’s health.</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="4cbf">In the <strong class="lw jq">Retraining </strong>section, I’ll show how I approached data versioning to manage my data and model artifacts for each retraining experiment while keeping data quality in mind. To do so, I used tools such as <a class="au lt" href="https://lakefs.io/" rel="noopener ugc nofollow" target="_blank"><strong class="lw jq">lakeFS</strong></a><strong class="lw jq">, </strong><a class="au lt" href="https://greatexpectations.io/" rel="noopener ugc nofollow" target="_blank"><strong class="lw jq">Great Expectations</strong></a><strong class="lw jq">, </strong>and <a class="au lt" href="https://wandb.ai/" rel="noopener ugc nofollow" target="_blank"><strong class="lw jq">W&amp;B</strong></a><strong class="lw jq">. </strong>Everything discussed in this part can be found at the <a class="au lt" href="https://github.com/FelipeAdachi/fake-news-experiments/blob/main/src/retrain/assert_commit_retrain.py" rel="noopener ugc nofollow" target="_blank">project’s repository</a><em class="nq">.</em></p></div><div class="o dx nr ns ii nt" role="separator"><span class="nu fl ci nv nw nx"></span><span class="nu fl ci nv nw nx"></span><span class="nu fl ci nv nw"></span></div><div class="iz ja jb jc jd"><h1 class="ny mr jg bm ms nz oa ob mw oc od oe na kv of kw nd ky og kz ng lb oh lc nj oi ga" id="0428">Monitoring</h1><p class="pw-post-body-paragraph lu lv jg lw b lx nk kq lz ma nl kt mc md nm mf mg mh nn mj mk ml no mn mo mp iz ga" id="87a7">Let’s begin by taking a look at the <code class="fp oj ok ol om b">model_predictions</code> table’s schema:</p><ul class=""><li class="on oo jg lw b lx ly ma mb md op mh oq ml or mp os ot ou ov ga" id="0b99"><strong class="lw jq">title (STRING): </strong>The new’s title.</li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="6fb5"><strong class="lw jq">content (STRING): </strong>The new’s text content.</li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="f700"><strong class="lw jq">model (STRING): </strong>The name of the model that generated the prediction.</li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="cc2d"><strong class="lw jq">prediction (STRING): </strong>The model’s prediction — “Real” or “Fake”.</li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="6aa1"><strong class="lw jq">confidence (FLOAT): </strong>The prediction’s level of confidence by the model. From 0 to 1.</li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="4056"><strong class="lw jq">url (STRING): </strong>The new’s URL.</li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="02e3"><strong class="lw jq">prediction_date (DATETIME): </strong>Date and time of when the prediction was made.</li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="81ee"><strong class="lw jq">ground_truth (STRING): </strong>Starts as NULL, and can be changed to “Real” or “Fake” in a labeling process.</li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="904f"><strong class="lw jq">coverage (FLOAT): </strong>The percentage of words in the news that are present in the model’s vocabulary.</li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="3365"><strong class="lw jq">word_count (INTEGER): </strong>The number of words in the news.</li></ul><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="60ea">These fields are all calculated upon serving the prediction’s online request by our application. If you’re interested in knowing how those metrics were calculated in the first place, you can take a look at <code class="fp oj ok ol om b">app.py</code> at the <a class="au lt" href="https://github.com/FelipeAdachi/fake-news-deploy" rel="noopener ugc nofollow" target="_blank">project’s repository</a>.</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="a02c">From these fields, we can set up an online dashboard with Google Data Studio to constantly monitor some indicators of our prediction model:</p><figure class="lf lg lh li gx lj gl gm paragraph-image"><div class="lk ll do lm ce ln" role="button" tabindex="0"><div class="gl gm pb"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*Qor1D64Ax3YxWKHUarg-aw.jpeg 640w, https://miro.medium.com/max/720/1*Qor1D64Ax3YxWKHUarg-aw.jpeg 720w, https://miro.medium.com/max/750/1*Qor1D64Ax3YxWKHUarg-aw.jpeg 750w, https://miro.medium.com/max/786/1*Qor1D64Ax3YxWKHUarg-aw.jpeg 786w, https://miro.medium.com/max/828/1*Qor1D64Ax3YxWKHUarg-aw.jpeg 828w, https://miro.medium.com/max/1100/1*Qor1D64Ax3YxWKHUarg-aw.jpeg 1100w, https://miro.medium.com/max/1400/1*Qor1D64Ax3YxWKHUarg-aw.jpeg 1400w"/><img alt="" class="ce lo lp c" height="523" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="lq bl gn gl gm lr ls bm b bn bo cn">Image by author</figcaption></figure><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="b9d5">Data Studio has a very intuitive interface. In this example, we’re using only one data source, which is the <code class="fp oj ok ol om b">model prediction</code> table at BigQuery. So, from a blank dashboard, we can add a data source by simply clicking the <strong class="lw jq">Add Data</strong> button at the top, and then selecting the BigQuery option.</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="8449">I chose not to display charts related to <code class="fp oj ok ol om b">ground_truth</code> , as this field can be frequently empty if there’s not an intention of retraining the model in the near future. But if labeling is done constantly, a <strong class="lw jq">Confusion Matrix</strong> would be a great addition to our dashboard.</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="8a6a">In this example, since I don’t have a great number of records, we shouldn’t draw any statistical conclusion from these numbers. Hopefully, in the future, with more daily predictions, these charts will be more informative. Nonetheless, let’s go by and discuss each one of these indicators:</p><h2 class="mq mr jg bm ms mt mu mv mw mx my mz na md nb nc nd mh ne nf ng ml nh ni nj jm ga" id="16d6">Records</h2><p class="pw-post-body-paragraph lu lv jg lw b lx nk kq lz ma nl kt mc md nm mf mg mh nn mj mk ml no mn mo mp iz ga" id="d24d">This is simply the number of predictions the application has served until now. To create it, go to <strong class="lw jq">Add a Chart </strong>at the top and select <strong class="lw jq">scorecard. </strong>Choose your table as <strong class="lw jq">Data Source </strong>and <strong class="lw jq">Record Count </strong>as <strong class="lw jq">Metric.</strong></p><h2 class="mq mr jg bm ms mt mu mv mw mx my mz na md nb nc nd mh ne nf ng ml nh ni nj jm ga" id="1a85">Labeled</h2><p class="pw-post-body-paragraph lu lv jg lw b lx nk kq lz ma nl kt mc md nm mf mg mh nn mj mk ml no mn mo mp iz ga" id="5994">This is the percentage of records that have been manually labeled. This is important for the next step of retraining. Without ground truth, you can’t retrain your model.</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="3320">Like <strong class="lw jq">Records,</strong> this is also a <strong class="lw jq">scorecard.</strong> But for this one, you have to create a new calculated field, by clicking <strong class="lw jq">ADD A FIELD</strong> at the bottom of the scorecard’s <strong class="lw jq">DATA </strong>tab:</p><figure class="lf lg lh li gx lj gl gm paragraph-image"><div class="lk ll do lm ce ln" role="button" tabindex="0"><div class="gl gm pc"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*-fSqwIl0Z652rw9t0LSYww.png 640w, https://miro.medium.com/max/720/1*-fSqwIl0Z652rw9t0LSYww.png 720w, https://miro.medium.com/max/750/1*-fSqwIl0Z652rw9t0LSYww.png 750w, https://miro.medium.com/max/786/1*-fSqwIl0Z652rw9t0LSYww.png 786w, https://miro.medium.com/max/828/1*-fSqwIl0Z652rw9t0LSYww.png 828w, https://miro.medium.com/max/1100/1*-fSqwIl0Z652rw9t0LSYww.png 1100w, https://miro.medium.com/max/1400/1*-fSqwIl0Z652rw9t0LSYww.png 1400w"/><img alt="" class="ce lo lp c" height="323" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="lq bl gn gl gm lr ls bm b bn bo cn">Screenshot by author</figcaption></figure><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="31a1">Then, just select the newly-created field as your <strong class="lw jq">Metric, </strong>just like before.</p><h2 class="mq mr jg bm ms mt mu mv mw mx my mz na md nb nc nd mh ne nf ng ml nh ni nj jm ga" id="a4b0">Current Model</h2><p class="pw-post-body-paragraph lu lv jg lw b lx nk kq lz ma nl kt mc md nm mf mg mh nn mj mk ml no mn mo mp iz ga" id="1f60">The name of the last prediction’s model. Assumes we have only one application, and there can only be one model at a time.</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="771b">This indicator is actually a <strong class="lw jq">Table </strong>chart, rather than a <strong class="lw jq">scorecard</strong>. As <strong class="lw jq">Dimension, </strong>select <code class="fp oj ok ol om b">model</code>and <code class="fp oj ok ol om b">prediction_date</code>, then set <strong class="lw jq">Rows per page </strong>as 1 and then sort <code class="fp oj ok ol om b">prediction_date</code> in <strong class="lw jq">Descending </strong>order. Then you should hide everything possible at the <strong class="lw jq">STYLE </strong>tab.</p><h2 class="mq mr jg bm ms mt mu mv mw mx my mz na md nb nc nd mh ne nf ng ml nh ni nj jm ga" id="19b5">Predictions</h2><p class="pw-post-body-paragraph lu lv jg lw b lx nk kq lz ma nl kt mc md nm mf mg mh nn mj mk ml no mn mo mp iz ga" id="8b49">The Real/Fake prediction’s percentage.</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="72d1">To create it, go to <strong class="lw jq">Add a Chart → Pie. </strong>Choose <code class="fp oj ok ol om b">prediction</code> as <strong class="lw jq">Dimension</strong>, and <strong class="lw jq">Record_count </strong>as <strong class="lw jq">Metric, </strong>and you’re good to go.</p><h2 class="mq mr jg bm ms mt mu mv mw mx my mz na md nb nc nd mh ne nf ng ml nh ni nj jm ga" id="3fdc">Prediction Metrics</h2><p class="pw-post-body-paragraph lu lv jg lw b lx nk kq lz ma nl kt mc md nm mf mg mh nn mj mk ml no mn mo mp iz ga" id="6360">This graph shows us the average of two values over time, on a weekly basis: <code class="fp oj ok ol om b">confidence</code>and <code class="fp oj ok ol om b">coverage</code><strong class="lw jq">. </strong>From this, we should be able to see an unusual change in the model’s level of confidence in its predictions, and also how much of the news is present on the trained model’s vocabulary. If the <code class="fp oj ok ol om b">coverage</code> has a descending trend and goes below a predefined threshold, it might be time to retrain it.</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="af2b">This one’s a <strong class="lw jq">Time series. </strong>On the <strong class="lw jq">Dimension </strong>field, at the little calendar icon, you should be able to set the period. I chose <strong class="lw jq">ISO Year Week. </strong>As <strong class="lw jq">Metric,</strong> choose <code class="fp oj ok ol om b">confidence</code> as the first one, and <strong class="lw jq">AVG </strong>as aggregation for the metric. Then, go to <strong class="lw jq">Add metric </strong>and do the same with <code class="fp oj ok ol om b">coverage.</code> At the <strong class="lw jq">STYLE </strong>tab, you can change both series from <strong class="lw jq">Lines </strong>to <strong class="lw jq">Bars </strong>and set their colors.</p><h2 class="mq mr jg bm ms mt mu mv mw mx my mz na md nb nc nd mh ne nf ng ml nh ni nj jm ga" id="9001"><strong class="ba">Word Count Frequency</strong></h2><p class="pw-post-body-paragraph lu lv jg lw b lx nk kq lz ma nl kt mc md nm mf mg mh nn mj mk ml no mn mo mp iz ga" id="88c8">This chart groups records by the number of words, according to each prediction category. Even though we need more data to have a real grasp of the word count distribution, it seems that Fake news is usually shorter than Real ones.</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="e067">Another strange detail is that there are 5 Fake predictions with a word count between 0–100. That seems a little low for a piece of news, which led me to investigate further. I eventually found out that these records were extracted from the same website, and they all had a parsing error. The content was not the actual news, but rather an error message. This is important, and we should make sure that these kinds of records will never be ingested into our training-test dataset.</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="a3c2">That was the closest I got to making a histogram at Data Studio. To create one go to <strong class="lw jq">Chart → Bar, </strong>and add a new field, at the bottom of the <strong class="lw jq">DATA </strong>tab. In the formula field, enter:</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="65f0"><code class="fp oj ok ol om b">FLOOR(word_count/100)*100</code></p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="72c6">For each record, the word count will be divided by 100, and then the largest integral value of the result is multiplied by 100. That will put the records into bins of hundreds. I named that field <code class="fp oj ok ol om b">wc_bin</code>. You can use it as the <strong class="lw jq">Dimension, </strong>and <strong class="lw jq">Record Count </strong>as <strong class="lw jq">Metric. </strong>You should also set <strong class="lw jq">Sort </strong>to <strong class="lw jq">Ascending</strong>, and choose <code class="fp oj ok ol om b">wc_bin</code> .</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="b2c9">To split the histograms into Fake and Real, you can go to <strong class="lw jq">Add a Filter, </strong>right below <strong class="lw jq">Sort, </strong>and insert a filter like this one:</p><figure class="lf lg lh li gx lj gl gm paragraph-image"><div class="lk ll do lm ce ln" role="button" tabindex="0"><div class="gl gm pd"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*g6TsEMmpSREQbrCWwrKgdw.png 640w, https://miro.medium.com/max/720/1*g6TsEMmpSREQbrCWwrKgdw.png 720w, https://miro.medium.com/max/750/1*g6TsEMmpSREQbrCWwrKgdw.png 750w, https://miro.medium.com/max/786/1*g6TsEMmpSREQbrCWwrKgdw.png 786w, https://miro.medium.com/max/828/1*g6TsEMmpSREQbrCWwrKgdw.png 828w, https://miro.medium.com/max/1100/1*g6TsEMmpSREQbrCWwrKgdw.png 1100w, https://miro.medium.com/max/1400/1*g6TsEMmpSREQbrCWwrKgdw.png 1400w"/><img alt="" class="ce lo lp c" height="151" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="lq bl gn gl gm lr ls bm b bn bo cn">Screenshot by author</figcaption></figure><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="c28a">And just do the opposite for the next category.</p></div><div class="o dx nr ns ii nt" role="separator"><span class="nu fl ci nv nw nx"></span><span class="nu fl ci nv nw nx"></span><span class="nu fl ci nv nw"></span></div><div class="iz ja jb jc jd"><h1 class="ny mr jg bm ms nz oa ob mw oc od oe na kv of kw nd ky og kz ng lb oh lc nj oi ga" id="4b43">Retraining</h1><p class="pw-post-body-paragraph lu lv jg lw b lx nk kq lz ma nl kt mc md nm mf mg mh nn mj mk ml no mn mo mp iz ga" id="66ef">Alright, now we have a way to check on our model’s health. If something is out of the usual, we could start labeling some of the records and take a look at some important classification metrics, such as <strong class="lw jq">Precision, Recall, and F-score. </strong>If you’re not happy with the results, we should start retraining the model.</p><h2 class="mq mr jg bm ms mt mu mv mw mx my mz na md nb nc nd mh ne nf ng ml nh ni nj jm ga" id="7d06">Overview</h2><p class="pw-post-body-paragraph lu lv jg lw b lx nk kq lz ma nl kt mc md nm mf mg mh nn mj mk ml no mn mo mp iz ga" id="d708">The image below is an overview of the retraining process I set up for this project:</p><figure class="lf lg lh li gx lj gl gm paragraph-image"><div class="lk ll do lm ce ln" role="button" tabindex="0"><div class="gl gm pe"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*BjMHBHkg0MfnlGwLpe8BHQ.jpeg 640w, https://miro.medium.com/max/720/1*BjMHBHkg0MfnlGwLpe8BHQ.jpeg 720w, https://miro.medium.com/max/750/1*BjMHBHkg0MfnlGwLpe8BHQ.jpeg 750w, https://miro.medium.com/max/786/1*BjMHBHkg0MfnlGwLpe8BHQ.jpeg 786w, https://miro.medium.com/max/828/1*BjMHBHkg0MfnlGwLpe8BHQ.jpeg 828w, https://miro.medium.com/max/1100/1*BjMHBHkg0MfnlGwLpe8BHQ.jpeg 1100w, https://miro.medium.com/max/1400/1*BjMHBHkg0MfnlGwLpe8BHQ.jpeg 1400w"/><img alt="" class="ce lo lp c" height="423" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="lq bl gn gl gm lr ls bm b bn bo cn">Image by author</figcaption></figure><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="a7d8">We have our <strong class="lw jq">Base Data</strong>, the <a class="au lt" href="https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset" rel="noopener ugc nofollow" target="_blank">original dataset</a> we used in order to train our first prediction model. In addition, the application is constantly feeding us data from the online predictions. So, in order to retrain the model, we can extract this data and do some simple preprocessing, such as removing duplicate news. It is also very important to validate our data and make sure it complies with some assumptions we have regarding the data’s shape and distribution. Then, we move on by joining both data sources to finally retrain the model. Before replacing the old model, we must evaluate the newly-trained model with a test set to make sure of its quality.</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="bce5">Every time we wish to retrain the model, we follow these steps. But if we notice something wrong in the future, how do we debug our model? To do so, we need an orderly manner to store our model and data artifacts, in addition to the model’s performance results and code that generated it.</p><h2 class="mq mr jg bm ms mt mu mv mw mx my mz na md nb nc nd mh ne nf ng ml nh ni nj jm ga" id="cb7e">Data Versioning with LakeFS</h2><p class="pw-post-body-paragraph lu lv jg lw b lx nk kq lz ma nl kt mc md nm mf mg mh nn mj mk ml no mn mo mp iz ga" id="ef15">Managing data pipelines in an ML Application is not an easy task. Unlike traditional software development, where GIT has become the standard for code versioning, data versioning is still at its early stages, and there’s not a “definitive” way of doing so.</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="1f68">I decided to treat each retraining process as a single experiment and store the artifacts of each experiment in a single branch. This is a little different from what we’re used to with code versioning because in this case, I don’t expect to merge the branches back into the trunk. They are short-lived branches with the purpose of versioning our artifacts — datasets and models — according to different retraining experiments.</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="e730">Even though there are a number of MLOps tools that provide data versioning functionality, such as <a class="au lt" href="https://mlflow.org/" rel="noopener ugc nofollow" target="_blank"><strong class="lw jq">MLflow</strong></a> and <a class="au lt" href="https://wandb.ai/home" rel="noopener ugc nofollow" target="_blank"><strong class="lw jq">W&amp;B</strong></a>, I opted to tackle <a class="au lt" href="https://lakefs.io/data-versioning-as-an-infrastructure/" rel="noopener ugc nofollow" target="_blank">data versioning as an infrastructure</a>, by enabling Git-like operations over my object storage. For that purpose, I decided to try out the recently-released <a class="au lt" href="https://lakefs.io/" rel="noopener ugc nofollow" target="_blank"><strong class="lw jq">lakeFS</strong></a>, which enables me to add the Git-like engine on top of my existing S3 object storage. That way, my data versioning capability for the project is independent of any tools that I might add or replace in the future.</p><h2 class="mq mr jg bm ms mt mu mv mw mx my mz na md nb nc nd mh ne nf ng ml nh ni nj jm ga" id="0191">Preliminary Steps — Deploying lakeFS</h2><p class="pw-post-body-paragraph lu lv jg lw b lx nk kq lz ma nl kt mc md nm mf mg mh nn mj mk ml no mn mo mp iz ga" id="b677">You can find the instructions to set up your lakeFS environment <a class="au lt" href="https://docs.lakefs.io/deploying/" rel="noopener ugc nofollow" target="_blank">here</a>.</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="9d3f">I basically had to:</p><ol class=""><li class="on oo jg lw b lx ly ma mb md op mh oq ml or mp pf ot ou ov ga" id="87a2"><a class="au lt" href="https://docs.lakefs.io/deploying/db.html" rel="noopener ugc nofollow" target="_blank">Create a PostgreSQL database</a> on AWS RDS</li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp pf ot ou ov ga" id="d2d0"><a class="au lt" href="https://docs.lakefs.io/deploying/bucket.html" rel="noopener ugc nofollow" target="_blank">Configure an S3 bucket</a> for my repository</li></ol><ul class=""><li class="on oo jg lw b lx ly ma mb md op mh oq ml or mp os ot ou ov ga" id="3e9a">For the policy’s Principal, I created a user and created access keys for it. I’ll also use this user to authenticate lakeFS to AWS. You can read more about <a class="au lt" href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/walkthrough1.html" rel="noopener ugc nofollow" target="_blank">here</a> and <a class="au lt" href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html" rel="noopener ugc nofollow" target="_blank">here</a>.</li></ul><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="09e1">3. <a class="au lt" href="https://docs.lakefs.io/deploying/install.html" rel="noopener ugc nofollow" target="_blank">Install lakeFS</a></p><ul class=""><li class="on oo jg lw b lx ly ma mb md op mh oq ml or mp os ot ou ov ga" id="cc46">I chose to install it via Docker, with the following command:</li></ul><pre class="lf lg lh li gx pg bs ph pi dz om"><span class="ga mq mr jg om b dm pj pk l pl pm" id="b7ab">docker run --name lakefs -p 8000:8000<br/>-e LAKEFS_DATABASE_CONNECTION_STRING="&lt;postgres-connection-str&gt;"<br/>-e LAKEFS_AUTH_ENCRYPT_SECRET_KEY="&lt;lakefs-secret-key&gt;"<br/>-e LAKEFS_BLOCKSTORE_TYPE="s3"<br/>-e LAKEFS_GATEWAYS_S3_DOMAIN_NAME="s3.local.lakefs.io"<br/>-e LAKEFS_BLOCKSTORE_S3_CREDENTIALS_ACCESS_SECRET_KEY="&lt;s3-secret-key&gt;"<br/>-e LAKEFS_BLOCKSTORE_S3_CREDENTIALS_ACCESS_KEY_ID="&lt;s3-access-key&gt;" -e LAKEFS_BLOCKSTORE_S3_REGION="&lt;s3-region&gt;" treeverse/lakefs:latest run</span></pre><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="c0b9">Where <code class="fp oj ok ol om b">postgres-connection-str</code> is the connection string you obtained creating the PostgreSQL DB, <code class="fp oj ok ol om b">lakefs-secret-key</code> is any randomly generated string (just don’t forget it), <code class="fp oj ok ol om b">s3-secret-key</code> and <code class="fp oj ok ol om b">s3-access-key</code> are the key-pair you created for your AWS User earlier, and <code class="fp oj ok ol om b">s3-region</code> is the region of the bucket you created.</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="777a">4. <a class="au lt" href="https://docs.lakefs.io/deploying/setup.html" rel="noopener ugc nofollow" target="_blank">Setup</a></p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="f9ce">At <strong class="lw jq">localhost:8000</strong>, after setting a new administrator user and creating the repository, you should be able to see your list of repositories:</p><figure class="lf lg lh li gx lj gl gm paragraph-image"><div class="lk ll do lm ce ln" role="button" tabindex="0"><div class="gl gm pn"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*HZG4Tfq34iVGVlE4TJGxSg.png 640w, https://miro.medium.com/max/720/1*HZG4Tfq34iVGVlE4TJGxSg.png 720w, https://miro.medium.com/max/750/1*HZG4Tfq34iVGVlE4TJGxSg.png 750w, https://miro.medium.com/max/786/1*HZG4Tfq34iVGVlE4TJGxSg.png 786w, https://miro.medium.com/max/828/1*HZG4Tfq34iVGVlE4TJGxSg.png 828w, https://miro.medium.com/max/1100/1*HZG4Tfq34iVGVlE4TJGxSg.png 1100w, https://miro.medium.com/max/1400/1*HZG4Tfq34iVGVlE4TJGxSg.png 1400w"/><img alt="" class="ce lo lp c" height="167" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="lq bl gn gl gm lr ls bm b bn bo cn">Screenshot by author</figcaption></figure><h2 class="mq mr jg bm ms mt mu mv mw mx my mz na md nb nc nd mh ne nf ng ml nh ni nj jm ga" id="ffa9">The Retraining Process</h2><p class="pw-post-body-paragraph lu lv jg lw b lx nk kq lz ma nl kt mc md nm mf mg mh nn mj mk ml no mn mo mp iz ga" id="767a">Now that we have everything set up, we need to translate that flowchart into a series of steps and implement it. We’ll basically need to:</p><ul class=""><li class="on oo jg lw b lx ly ma mb md op mh oq ml or mp os ot ou ov ga" id="94b9">Get data from online predictions (<strong class="lw jq">BigQuery</strong>)</li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="8d67">Clean and assert data quality (<strong class="lw jq">Great Expectations</strong>)</li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="1c50">Create a new branch from master (<strong class="lw jq">lakeFS</strong>)</li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="f629">Upload online predictions to a new branch (<strong class="lw jq">lakeFS</strong>)</li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="b4e1">Get base data from master branch (<strong class="lw jq">lakeFS</strong>)</li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="ac2a">Join online predictions to base data and split to train-test datasets</li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="7654">Upload train-test splits to branch (<strong class="lw jq">lakeFS</strong>)</li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="a7f6">Train model with the updated dataset</li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="abc3">Log Experiment/Results (<strong class="lw jq">W&amp;B</strong>)</li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="0181">Upload Model and Vocabulary to branch (<strong class="lw jq">lakeFS</strong>)</li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="5b4f">Commit changes to branch (<strong class="lw jq">lakeFS</strong>)</li></ul><h2 class="mq mr jg bm ms mt mu mv mw mx my mz na md nb nc nd mh ne nf ng ml nh ni nj jm ga" id="cd5d">Data Structure</h2><p class="pw-post-body-paragraph lu lv jg lw b lx nk kq lz ma nl kt mc md nm mf mg mh nn mj mk ml no mn mo mp iz ga" id="9ec5">As for our data structure, we’ll define as <code class="fp oj ok ol om b">external</code> data our original dataset as well as data extracted from the web app’s online predictions. The <code class="fp oj ok ol om b">interim</code> folder will keep our data once the external sources are combined and split into appropriate train-test sets. The model files will also be stored in their own folder.</p><figure class="lf lg lh li gx lj gl gm paragraph-image"><div class="gl gm po"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 383px" srcset="https://miro.medium.com/max/640/1*VguE8l2ZXmEczlydl3FYRg.png 640w, https://miro.medium.com/max/720/1*VguE8l2ZXmEczlydl3FYRg.png 720w, https://miro.medium.com/max/750/1*VguE8l2ZXmEczlydl3FYRg.png 750w, https://miro.medium.com/max/786/1*VguE8l2ZXmEczlydl3FYRg.png 786w, https://miro.medium.com/max/828/1*VguE8l2ZXmEczlydl3FYRg.png 828w, https://miro.medium.com/max/1100/1*VguE8l2ZXmEczlydl3FYRg.png 1100w, https://miro.medium.com/max/766/1*VguE8l2ZXmEczlydl3FYRg.png 766w"/><img alt="" class="ce lo lp c" height="300" loading="lazy" role="presentation" width="383"/></picture></div><figcaption class="lq bl gn gl gm lr ls bm b bn bo cn">Image by author</figcaption></figure><h2 class="mq mr jg bm ms mt mu mv mw mx my mz na md nb nc nd mh ne nf ng ml nh ni nj jm ga" id="299b"><strong class="ba">Get Data From Production</strong></h2><p class="pw-post-body-paragraph lu lv jg lw b lx nk kq lz ma nl kt mc md nm mf mg mh nn mj mk ml no mn mo mp iz ga" id="7072">First, we need to get the new data from our BigQuery table. To use the Python APIs for accessing BigQuery, I need GCP credentials in JSON format. After creating a project, you can follow these instructions on <em class="nq">“creating a service account” </em>in this <a class="au lt" href="https://cloud.google.com/docs/authentication/getting-started" rel="noopener ugc nofollow" target="_blank">Google documentation</a> in order to download your credentials.</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="b1ab">Then, installing <code class="fp oj ok ol om b">google-cloud-bigquery</code> and setting an environment variable indicating the location of your credentials and initiating the BigQuery client should be enough for you to query your table. In this case, <code class="fp oj ok ol om b">sunny-emissary-293912</code> is the name of my project, <code class="fp oj ok ol om b">fakenewsdeploy</code> the name of my dataset and <code class="fp oj ok ol om b">model_predictions</code> the name of my table.</p><figure class="lf lg lh li gx lj"><div class="m fs l do"><div class="pp pq l"></div></div></figure><h2 class="mq mr jg bm ms mt mu mv mw mx my mz na md nb nc nd mh ne nf ng ml nh ni nj jm ga" id="e9c6">Clean And Assert Quality</h2><p class="pw-post-body-paragraph lu lv jg lw b lx nk kq lz ma nl kt mc md nm mf mg mh nn mj mk ml no mn mo mp iz ga" id="4239">We should always ensure the quality of data ingested into our storage. A great way to do that is using the tool <a class="au lt" href="https://greatexpectations.io/" rel="noopener ugc nofollow" target="_blank"><strong class="lw jq">Great Expectations</strong></a>. After I do some very simple cleaning, like removing duplicate news and news with low word count, we can do some basic assumptions about what we expect from our data.</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="20e2">In this example, we’ll only keep going with our retraining if our data passes some validations. The <code class="fp oj ok ol om b">ground_truth</code> should assume only <code class="fp oj ok ol om b">Fake</code> or <code class="fp oj ok ol om b">Real</code> values, the <code class="fp oj ok ol om b">url</code> value should be unique and every sample should have a non-null <code class="fp oj ok ol om b">content.</code> In addition, we assume that an excessively low <code class="fp oj ok ol om b">coverage</code> must be investigated, as it might be a sign of parsing errors, or maybe content in another language. Finally, the <code class="fp oj ok ol om b">word_count</code> should be above 100, as we have discussed previously in the <strong class="lw jq">Monitoring </strong>section of this article.</p><figure class="lf lg lh li gx lj"><div class="m fs l do"><div class="pp pq l"></div></div></figure><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="7029">We can then generate an <code class="fp oj ok ol om b">expectation_suite</code> , which gives us a JSON file showing the validations passed by our data. We should also make sure to store this information for future reference (which will be done in the sequence).</p><figure class="lf lg lh li gx lj"><div class="m fs l do"><div class="pp pq l"></div></div></figure><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="c003">We are only scratching the surface with Great Expectations here. Check out <a class="au lt" href="https://greatexpectations.io/" rel="noopener ugc nofollow" target="_blank">their website</a> to know more functionalities.</p><h2 class="mq mr jg bm ms mt mu mv mw mx my mz na md nb nc nd mh ne nf ng ml nh ni nj jm ga" id="2c05">Create new Branch</h2><p class="pw-post-body-paragraph lu lv jg lw b lx nk kq lz ma nl kt mc md nm mf mg mh nn mj mk ml no mn mo mp iz ga" id="89ef">Now that we trust our data, we can store it in a newly-created branch. In the early stages of <a class="au lt" href="/how-i-learned-to-stop-worrying-and-track-my-machine-learning-experiments-d9f2dfe8e4b3" rel="noopener" target="_blank"><strong class="lw jq">Model Building/Evaluation </strong>of this project</a>, I used <strong class="lw jq">W&amp;B</strong> to track my experiments. I’ll keep using it during the retraining process, in conjunction with lakeFS. This way, the experiment identifier is the wandb’s run name, and I’ll just use the same name in order to create the branch:</p><figure class="lf lg lh li gx lj"><div class="m fs l do"><div class="pp pq l"></div></div></figure><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="4e9e">Two things to point out here. In line 3, while starting the run, you see I configured a threshold. That’s for a nice W&amp;B functionality where I can set up a threshold to be monitored during training. In this case, if the <strong class="lw jq">F1-Score</strong> of the trained model is below <strong class="lw jq">0.9</strong>, W&amp;B will send me an email letting me know. We’ll see the rest of it in the training code.</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="c57b">Another important issue here is how I’m doing operations at my lakeFS repository. This can be done <a class="au lt" href="https://docs.lakefs.io/using/" rel="noopener ugc nofollow" target="_blank">in several different ways</a>, but I chose to use the Python client. I created a <code class="fp oj ok ol om b">lakefs_connector</code> class to wrap the APIs into more tailored functions for my application. The class implementation is shown at the end of this article.</p><h2 class="mq mr jg bm ms mt mu mv mw mx my mz na md nb nc nd mh ne nf ng ml nh ni nj jm ga" id="8f2c">Upload Online Predictions to Branch</h2><p class="pw-post-body-paragraph lu lv jg lw b lx nk kq lz ma nl kt mc md nm mf mg mh nn mj mk ml no mn mo mp iz ga" id="a3a0">Let’s keep going by uploading <code class="fp oj ok ol om b">online_predictions.csv</code> to our branch. We’ll also save <code class="fp oj ok ol om b">my_expectation_file.json</code> to our wandb run.</p><figure class="lf lg lh li gx lj"><div class="m fs l do"><div class="pp pq l"></div></div></figure><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="e1ab">Now we can access our expectation file whenever we need it, and make sure that the data’s state at this particular run complies with our assumptions:</p><figure class="lf lg lh li gx lj gl gm paragraph-image"><div class="lk ll do lm ce ln" role="button" tabindex="0"><div class="gl gm pr"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*W8b0nSSDotMFAOYYF7oApQ.png 640w, https://miro.medium.com/max/720/1*W8b0nSSDotMFAOYYF7oApQ.png 720w, https://miro.medium.com/max/750/1*W8b0nSSDotMFAOYYF7oApQ.png 750w, https://miro.medium.com/max/786/1*W8b0nSSDotMFAOYYF7oApQ.png 786w, https://miro.medium.com/max/828/1*W8b0nSSDotMFAOYYF7oApQ.png 828w, https://miro.medium.com/max/1100/1*W8b0nSSDotMFAOYYF7oApQ.png 1100w, https://miro.medium.com/max/1400/1*W8b0nSSDotMFAOYYF7oApQ.png 1400w"/><img alt="" class="ce lo lp c" height="419" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="lq bl gn gl gm lr ls bm b bn bo cn">Screenshot by author</figcaption></figure><h2 class="mq mr jg bm ms mt mu mv mw mx my mz na md nb nc nd mh ne nf ng ml nh ni nj jm ga" id="3527">Merge Data and Split</h2><p class="pw-post-body-paragraph lu lv jg lw b lx nk kq lz ma nl kt mc md nm mf mg mh nn mj mk ml no mn mo mp iz ga" id="ed42">Our base data is comprised of two files: <code class="fp oj ok ol om b">True.csv</code> and <code class="fp oj ok ol om b">Fake.csv</code>, both previously uploaded into our master branch. Let’s append the data from <code class="fp oj ok ol om b">online_predictions.csv</code> to our base data and then split it into train-test datasets:</p><figure class="lf lg lh li gx lj"><div class="m fs l do"><div class="pp pq l"></div></div></figure><h2 class="mq mr jg bm ms mt mu mv mw mx my mz na md nb nc nd mh ne nf ng ml nh ni nj jm ga" id="ea5e">Train Model and Upload Artifacts</h2><p class="pw-post-body-paragraph lu lv jg lw b lx nk kq lz ma nl kt mc md nm mf mg mh nn mj mk ml no mn mo mp iz ga" id="56b1">The last series of steps is to finally train the model and upload our artifacts to the repository’s branch:</p><figure class="lf lg lh li gx lj"><div class="m fs l do"><div class="pp pq l"></div></div></figure><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="9129">We’ll upload the train-test splits as well as our model’s files — the actual <code class="fp oj ok ol om b">joblib</code> model and the vocabulary used for our Vectorizer (which is also used to calculate our <code class="fp oj ok ol om b">coverage</code> field).</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="d370">You can check the whole code for training the model <a class="au lt" href="https://github.com/FelipeAdachi/fake-news-experiments/blob/main/src/models/train_final.py" rel="noopener ugc nofollow" target="_blank">here</a>. I won’t get into specifics, since I already covered it in my <a class="au lt" href="/how-i-learned-to-stop-worrying-and-track-my-machine-learning-experiments-d9f2dfe8e4b3" rel="noopener" target="_blank">previous article</a>. I just want to point out an excerpt of it, related to the alert configuration we set up:</p><figure class="lf lg lh li gx lj"><div class="m fs l do"><div class="pp pq l"></div></div></figure><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="7d2d"><code class="fp oj ok ol om b">f1_score</code> is the calculated F1-Score during the training process. Since we set up the threshold of 0.9 previously, if the score for this run ends up below this value, an alert will be sent to the configured destination. In my case, it’s my email:</p><figure class="lf lg lh li gx lj gl gm paragraph-image"><div class="lk ll do lm ce ln" role="button" tabindex="0"><div class="gl gm ps"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*C8wBBkMh79Ctkat0osCxQw.png 640w, https://miro.medium.com/max/720/1*C8wBBkMh79Ctkat0osCxQw.png 720w, https://miro.medium.com/max/750/1*C8wBBkMh79Ctkat0osCxQw.png 750w, https://miro.medium.com/max/786/1*C8wBBkMh79Ctkat0osCxQw.png 786w, https://miro.medium.com/max/828/1*C8wBBkMh79Ctkat0osCxQw.png 828w, https://miro.medium.com/max/1100/1*C8wBBkMh79Ctkat0osCxQw.png 1100w, https://miro.medium.com/max/1400/1*C8wBBkMh79Ctkat0osCxQw.png 1400w"/><img alt="" class="ce lo lp c" height="81" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="lq bl gn gl gm lr ls bm b bn bo cn">Screenshot by author</figcaption></figure><h2 class="mq mr jg bm ms mt mu mv mw mx my mz na md nb nc nd mh ne nf ng ml nh ni nj jm ga" id="8c4b">Commit Changes</h2><p class="pw-post-body-paragraph lu lv jg lw b lx nk kq lz ma nl kt mc md nm mf mg mh nn mj mk ml no mn mo mp iz ga" id="9bb7">Now, what is left to do is to commit our changes into our branch:</p><figure class="lf lg lh li gx lj"><div class="m fs l do"><div class="pp pq l"></div></div></figure><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="80e0">And we’ll have our data separated according to our retraining experiments, like this:</p><figure class="lf lg lh li gx lj gl gm paragraph-image"><div class="lk ll do lm ce ln" role="button" tabindex="0"><div class="gl gm pt"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*yOx8us7blP0UGBLsp9xNTQ.png 640w, https://miro.medium.com/max/720/1*yOx8us7blP0UGBLsp9xNTQ.png 720w, https://miro.medium.com/max/750/1*yOx8us7blP0UGBLsp9xNTQ.png 750w, https://miro.medium.com/max/786/1*yOx8us7blP0UGBLsp9xNTQ.png 786w, https://miro.medium.com/max/828/1*yOx8us7blP0UGBLsp9xNTQ.png 828w, https://miro.medium.com/max/1100/1*yOx8us7blP0UGBLsp9xNTQ.png 1100w, https://miro.medium.com/max/1400/1*yOx8us7blP0UGBLsp9xNTQ.png 1400w"/><img alt="" class="ce lo lp c" height="353" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="lq bl gn gl gm lr ls bm b bn bo cn">Screenshot by author</figcaption></figure><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="2187">Since the run names are unique, we can easily match the data with our retraining’s results at our experiments dashboard at W&amp;B:</p><figure class="lf lg lh li gx lj gl gm paragraph-image"><div class="lk ll do lm ce ln" role="button" tabindex="0"><div class="gl gm pu"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*dsLrg9QvYtbTIqnVmTOZ2Q.png 640w, https://miro.medium.com/max/720/1*dsLrg9QvYtbTIqnVmTOZ2Q.png 720w, https://miro.medium.com/max/750/1*dsLrg9QvYtbTIqnVmTOZ2Q.png 750w, https://miro.medium.com/max/786/1*dsLrg9QvYtbTIqnVmTOZ2Q.png 786w, https://miro.medium.com/max/828/1*dsLrg9QvYtbTIqnVmTOZ2Q.png 828w, https://miro.medium.com/max/1100/1*dsLrg9QvYtbTIqnVmTOZ2Q.png 1100w, https://miro.medium.com/max/1400/1*dsLrg9QvYtbTIqnVmTOZ2Q.png 1400w"/><img alt="" class="ce lo lp c" height="233" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="lq bl gn gl gm lr ls bm b bn bo cn">Screenshot by author</figcaption></figure><h2 class="mq mr jg bm ms mt mu mv mw mx my mz na md nb nc nd mh ne nf ng ml nh ni nj jm ga" id="2c0b">The lakeFS connector</h2><p class="pw-post-body-paragraph lu lv jg lw b lx nk kq lz ma nl kt mc md nm mf mg mh nn mj mk ml no mn mo mp iz ga" id="181b">In the code snippets above, we have done some operations to our repository, such as creating branches, downloading and uploading objects, and committing changes. To do so, I used <a class="au lt" href="https://bravado.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank"><strong class="lw jq">bravado</strong></a> to generate a dynamic client, as instructed <a class="au lt" href="https://docs.lakefs.io/using/python.html" rel="noopener ugc nofollow" target="_blank">here</a>. This way we have access to all of the lakeFS’ APIs as Python commands.</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="f225">By instantiating the <code class="fp oj ok ol om b">lakefs_conn</code> class, we create a lakeFS client, and do the required repository operations through the object’s methods:</p><figure class="lf lg lh li gx lj"><div class="m fs l do"><div class="pp pq l"></div></div></figure></div><div class="o dx nr ns ii nt" role="separator"><span class="nu fl ci nv nw nx"></span><span class="nu fl ci nv nw nx"></span><span class="nu fl ci nv nw"></span></div><div class="iz ja jb jc jd"><h1 class="ny mr jg bm ms nz oa ob mw oc od oe na kv of kw nd ky og kz ng lb oh lc nj oi ga" id="b594">What’s Next</h1><p class="pw-post-body-paragraph lu lv jg lw b lx nk kq lz ma nl kt mc md nm mf mg mh nn mj mk ml no mn mo mp iz ga" id="802b">I wanted to share with you my take on monitoring my model’s performance and retraining it, but this is really the first step of a long process. As time goes on, the additional data enables us to have more insights, and we eventually discover better ways to monitor our application.</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="0385">For example, in the future, we could plot the performance of multiple retrained models and compare them over time, to more accurately assess the impact of time over our predictions. Or, given enough ground truth information, we could add metrics such as precision and recall to our dashboard.</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="4b9f">As for the retraining part, much can be improved. As we discover more about our data’s distribution, additional expectations can be added to our assertion stage. The addition of hooks for automatic pre-commit validation is also a natural evolution. Webhooks weren’t yet supported by lakeFS during the writing of this article, but it’s already an available feat since the latest release (0.33).</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="b3ef">That’s it for now! If you have any feedback or questions, feel free to reach out!</p><p class="pw-post-body-paragraph lu lv jg lw b lx ly kq lz ma mb kt mc md me mf mg mh mi mj mk ml mm mn mo mp iz ga" id="bc64">Thank you for reading!</p><h1 class="ny mr jg bm ms nz pv ob mw oc pw oe na kv px kw nd ky py kz ng lb pz lc nj oi ga" id="3286">References</h1><ul class=""><li class="on oo jg lw b lx nk ma nl md qa mh qb ml qc mp os ot ou ov ga" id="0ca5"><a class="au lt" href="https://martinfowler.com/articles/cd4ml.html" rel="noopener ugc nofollow" target="_blank">Continuous Delivery for Machine Learning</a></li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="9b8d"><a class="au lt" href="https://emilygorcenski.com/post/data-versioning" rel="noopener ugc nofollow" target="_blank">Data Versioning</a></li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="bdb3"><a class="au lt" href="https://lakefs.io/ensuring-data-quality-in-a-data-lake-environment/" rel="noopener ugc nofollow" target="_blank">Ensuring Data Quality in a Data Lake Environment</a></li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="a9ac"><a class="au lt" href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/aad9f93b86b7addfea4c419b9100c6cdd26cacea.pdf" rel="noopener ugc nofollow" target="_blank">The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction</a></li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="b6ee"><a class="au lt" href="https://lakefs.io/data-versioning-as-an-infrastructure/" rel="noopener ugc nofollow" target="_blank">Why Data Versioning as an Infrastructure Matters</a></li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="d948"><a class="au lt" href="https://docs.lakefs.io/" rel="noopener ugc nofollow" target="_blank">lakeFS — Documentation</a></li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="d303"><a class="au lt" href="https://docs.greatexpectations.io/en/latest/" rel="noopener ugc nofollow" target="_blank">Great Expectations — Documentation</a></li><li class="on oo jg lw b lx ow ma ox md oy mh oz ml pa mp os ot ou ov ga" id="3f65"><a class="au lt" href="https://docs.wandb.ai/" rel="noopener ugc nofollow" target="_blank">Weights and Biases — Documentation</a></li></ul></div></div></section></div></div></article>