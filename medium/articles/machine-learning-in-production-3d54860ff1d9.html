<article><div class="l"><div class="ig ih ii ij ik il im ce in ch l"></div><div class="l"><header class="pw-post-byline-header io ip iq ir is it iu iv iw ix l"><div class="o iy u"><div class="o"><div class="hq l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://asjadanis128.medium.com/?source=post_page-----3d54860ff1d9--------------------------------" rel="noopener follow"><div class="l do"><img alt="asjad anis" class="l ch gx iz ja hb" height="48" loading="lazy" src="https://miro.medium.com/fit/c/96/96/1*J16zDbTwS02dg08uML5tCQ.jpeg" width="48"/><div class="gw gx l iz ja ha aq"></div></div></a></div><div class="l"><div class="pw-author bm b dm dn gl"><div class="jb o hd"><div><div aria-hidden="false" class="ci"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://asjadanis128.medium.com/?source=post_page-----3d54860ff1d9--------------------------------" rel="noopener follow">asjad anis</a></div></div><div class="jc jd je jf i d"><span><a class="bm b fc bo fs jg ft fu fv fw fx bd bz fy fz ga cd cf cg ch ci cj" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F46e3b4d207b6&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-production-3d54860ff1d9&amp;user=asjad+anis&amp;userId=46e3b4d207b6&amp;source=post_page-46e3b4d207b6----3d54860ff1d9---------------------follow_byline-----------" rel="noopener follow">Follow</a></span></div></div></div><div class="o ao jh"><p class="pw-published-date bm b bn bo cn"><span>Nov 28, 2020</span></p><div aria-hidden="true" class="ji ci"><span aria-hidden="true" class="l"><span class="bm b bn bo cn">·</span></span></div><div class="pw-reading-time bm b bn bo cn">11 min read</div></div></div></div><div class="o ao"><div class="h k jj jk jl"><div class="jm l hs"><div><div aria-hidden="false" class="ci"><button aria-label="Share on twitter" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci jn dw jo"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M20 5.34c-.67.41-1.4.7-2.18.87a3.45 3.45 0 0 0-5.02-.1 3.49 3.49 0 0 0-1.02 2.47c0 .28.03.54.07.8a9.91 9.91 0 0 1-7.17-3.66 3.9 3.9 0 0 0-.5 1.74 3.6 3.6 0 0 0 1.56 2.92 3.36 3.36 0 0 1-1.55-.44V10c0 1.67 1.2 3.08 2.8 3.42-.3.06-.6.1-.94.12l-.62-.06a3.5 3.5 0 0 0 3.24 2.43 7.34 7.34 0 0 1-4.36 1.49l-.81-.05a9.96 9.96 0 0 0 5.36 1.56c6.4 0 9.91-5.32 9.9-9.9v-.5c.69-.49 1.28-1.1 1.74-1.81-.63.3-1.3.48-2 .56A3.33 3.33 0 0 0 20 5.33" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="jm l hs"><div><div aria-hidden="false" class="ci"><button aria-label="Share on facebook" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci jn dw jo"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 12.04c0-4.3-3.47-7.79-7.75-7.79a7.77 7.77 0 0 0-5.9 12.84 7.77 7.77 0 0 0 4.69 2.63v-5.49h-1.9v-2.2h1.9v-1.62c0-1.88 1.14-2.9 2.8-2.9.8 0 1.49.06 1.69.08v1.97h-1.15c-.91 0-1.1.43-1.1 1.07v1.4h2.17l-.28 2.2h-1.88v5.52a7.77 7.77 0 0 0 6.7-7.71" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="jm l hs"><div><div aria-hidden="false" class="ci"><button aria-label="Share on linkedin" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci jn dw jo"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 5.39v13.22a1.14 1.14 0 0 1-1.14 1.14H5.39a1.14 1.14 0 0 1-1.14-1.14V5.39a1.14 1.14 0 0 1 1.14-1.14h13.22a1.14 1.14 0 0 1 1.14 1.14zM8.81 10.18H6.53v7.3H8.8v-7.3zM9 7.67a1.31 1.31 0 0 0-1.3-1.32h-.04a1.32 1.32 0 0 0 0 2.64A1.31 1.31 0 0 0 9 7.71v-.04zm8.46 5.37c0-2.2-1.4-3.05-2.78-3.05a2.6 2.6 0 0 0-2.3 1.18h-.07v-1h-2.14v7.3h2.28V13.6a1.51 1.51 0 0 1 1.36-1.63h.09c.72 0 1.26.45 1.26 1.6v3.91h2.28l.02-4.43z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="l hs"><div><div aria-hidden="false" class="ci"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci jn dw jo"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path clip-rule="evenodd" d="M3.57 14.67c0-.57.13-1.11.38-1.6l.02-.02v-.02l.02-.02c0-.02 0-.02.02-.02.12-.26.3-.52.57-.8L7.78 9v-.02l.01-.02c.44-.41.91-.7 1.44-.85a4.87 4.87 0 0 0-1.19 2.36A5.04 5.04 0 0 0 8 11.6L6.04 13.6c-.19.19-.32.4-.38.65a2 2 0 0 0 0 .9c.08.2.2.4.38.57l1.29 1.31c.27.28.62.42 1.03.42.42 0 .78-.14 1.06-.42l1.23-1.25.79-.78 1.15-1.16c.08-.09.19-.22.28-.4.1-.2.15-.42.15-.67 0-.16-.02-.3-.06-.45l-.02-.02v-.02l-.07-.14s0-.03-.04-.06l-.06-.13-.02-.02c0-.02 0-.03-.02-.05a.6.6 0 0 0-.14-.16l-.48-.5c0-.04.02-.1.04-.15l.06-.12 1.17-1.14.09-.09.56.57c.02.04.08.1.16.18l.05.04.03.06.04.05.03.04.04.06.1.14.02.02c0 .02.01.03.03.04l.1.2v.02c.1.16.2.38.3.68a1 1 0 0 1 .04.25 3.2 3.2 0 0 1 .02 1.33 3.49 3.49 0 0 1-.95 1.87l-.66.67-.97.97-1.56 1.57a3.4 3.4 0 0 1-2.47 1.02c-.97 0-1.8-.34-2.49-1.03l-1.3-1.3a3.55 3.55 0 0 1-1-2.51v-.01h-.02v.02zm5.39-3.43c0-.19.02-.4.07-.63.13-.74.44-1.37.95-1.87l.66-.67.97-.98 1.56-1.56c.68-.69 1.5-1.03 2.47-1.03.97 0 1.8.34 2.48 1.02l1.3 1.32a3.48 3.48 0 0 1 1 2.48c0 .58-.11 1.11-.37 1.6l-.02.02v.02l-.02.04c-.14.27-.35.54-.6.8L16.23 15l-.01.02-.01.02c-.44.42-.92.7-1.43.83a4.55 4.55 0 0 0 1.23-3.52L18 10.38c.18-.21.3-.42.35-.65a2.03 2.03 0 0 0-.01-.9 1.96 1.96 0 0 0-.36-.58l-1.3-1.3a1.49 1.49 0 0 0-1.06-.42c-.42 0-.77.14-1.06.4l-1.2 1.27-.8.8-1.16 1.15c-.08.08-.18.21-.29.4a1.66 1.66 0 0 0-.08 1.12l.02.03v.02l.06.14s.01.03.05.06l.06.13.02.02.01.02.01.02c.05.08.1.13.14.16l.47.5c0 .04-.02.09-.04.15l-.06.12-1.15 1.15-.1.08-.56-.56a2.3 2.3 0 0 0-.18-.19c-.02-.01-.02-.03-.02-.04l-.02-.02a.37.37 0 0 1-.1-.12c-.03-.03-.05-.04-.05-.06l-.1-.15-.02-.02-.02-.04-.08-.17v-.02a5.1 5.1 0 0 1-.28-.69 1.03 1.03 0 0 1-.04-.26c-.06-.23-.1-.46-.1-.7v.01z" fill="#A8A8A8" fill-rule="evenodd"></path></svg></span></button></div></div></div><div class="jp o ao"><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3d54860ff1d9&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-production-3d54860ff1d9&amp;source=--------------------------bookmark_header-----------" rel="noopener follow"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="au de aw ax ay az ba jn bc gs jr js jt"><svg aria-label="Add to list bookmark button" class="jq" fill="none" height="25" viewbox="0 0 25 25" width="25"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></button></a></span></div></div><div class="ck ju"><div><div aria-hidden="false" class="ci"></div></div></div></div></div><div class="jv eu ew j i d"><div class="hq l"><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3d54860ff1d9&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-in-production-3d54860ff1d9&amp;source=--------------------------bookmark_header-----------" rel="noopener follow"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="au de aw jw ay az ba jx bc gs cd o ao jy jz jt"><svg aria-label="Add to list bookmark button" class="jq" fill="none" height="25" viewbox="0 0 25 25" width="25"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg><p class="bm b bn bo cn">Save</p></button></a></span></div><div class="ka l hs"><div><div aria-hidden="false" class="ci"><button aria-label="Share on twitter" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci jn dw jo"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M20 5.34c-.67.41-1.4.7-2.18.87a3.45 3.45 0 0 0-5.02-.1 3.49 3.49 0 0 0-1.02 2.47c0 .28.03.54.07.8a9.91 9.91 0 0 1-7.17-3.66 3.9 3.9 0 0 0-.5 1.74 3.6 3.6 0 0 0 1.56 2.92 3.36 3.36 0 0 1-1.55-.44V10c0 1.67 1.2 3.08 2.8 3.42-.3.06-.6.1-.94.12l-.62-.06a3.5 3.5 0 0 0 3.24 2.43 7.34 7.34 0 0 1-4.36 1.49l-.81-.05a9.96 9.96 0 0 0 5.36 1.56c6.4 0 9.91-5.32 9.9-9.9v-.5c.69-.49 1.28-1.1 1.74-1.81-.63.3-1.3.48-2 .56A3.33 3.33 0 0 0 20 5.33" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="ka l hs"><div><div aria-hidden="false" class="ci"><button aria-label="Share on facebook" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci jn dw jo"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 12.04c0-4.3-3.47-7.79-7.75-7.79a7.77 7.77 0 0 0-5.9 12.84 7.77 7.77 0 0 0 4.69 2.63v-5.49h-1.9v-2.2h1.9v-1.62c0-1.88 1.14-2.9 2.8-2.9.8 0 1.49.06 1.69.08v1.97h-1.15c-.91 0-1.1.43-1.1 1.07v1.4h2.17l-.28 2.2h-1.88v5.52a7.77 7.77 0 0 0 6.7-7.71" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="ka l hs"><div><div aria-hidden="false" class="ci"><button aria-label="Share on linkedin" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci jn dw jo"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 5.39v13.22a1.14 1.14 0 0 1-1.14 1.14H5.39a1.14 1.14 0 0 1-1.14-1.14V5.39a1.14 1.14 0 0 1 1.14-1.14h13.22a1.14 1.14 0 0 1 1.14 1.14zM8.81 10.18H6.53v7.3H8.8v-7.3zM9 7.67a1.31 1.31 0 0 0-1.3-1.32h-.04a1.32 1.32 0 0 0 0 2.64A1.31 1.31 0 0 0 9 7.71v-.04zm8.46 5.37c0-2.2-1.4-3.05-2.78-3.05a2.6 2.6 0 0 0-2.3 1.18h-.07v-1h-2.14v7.3h2.28V13.6a1.51 1.51 0 0 1 1.36-1.63h.09c.72 0 1.26.45 1.26 1.6v3.91h2.28l.02-4.43z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="l hs"><div><div aria-hidden="false" class="ci"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci jn dw jo"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path clip-rule="evenodd" d="M3.57 14.67c0-.57.13-1.11.38-1.6l.02-.02v-.02l.02-.02c0-.02 0-.02.02-.02.12-.26.3-.52.57-.8L7.78 9v-.02l.01-.02c.44-.41.91-.7 1.44-.85a4.87 4.87 0 0 0-1.19 2.36A5.04 5.04 0 0 0 8 11.6L6.04 13.6c-.19.19-.32.4-.38.65a2 2 0 0 0 0 .9c.08.2.2.4.38.57l1.29 1.31c.27.28.62.42 1.03.42.42 0 .78-.14 1.06-.42l1.23-1.25.79-.78 1.15-1.16c.08-.09.19-.22.28-.4.1-.2.15-.42.15-.67 0-.16-.02-.3-.06-.45l-.02-.02v-.02l-.07-.14s0-.03-.04-.06l-.06-.13-.02-.02c0-.02 0-.03-.02-.05a.6.6 0 0 0-.14-.16l-.48-.5c0-.04.02-.1.04-.15l.06-.12 1.17-1.14.09-.09.56.57c.02.04.08.1.16.18l.05.04.03.06.04.05.03.04.04.06.1.14.02.02c0 .02.01.03.03.04l.1.2v.02c.1.16.2.38.3.68a1 1 0 0 1 .04.25 3.2 3.2 0 0 1 .02 1.33 3.49 3.49 0 0 1-.95 1.87l-.66.67-.97.97-1.56 1.57a3.4 3.4 0 0 1-2.47 1.02c-.97 0-1.8-.34-2.49-1.03l-1.3-1.3a3.55 3.55 0 0 1-1-2.51v-.01h-.02v.02zm5.39-3.43c0-.19.02-.4.07-.63.13-.74.44-1.37.95-1.87l.66-.67.97-.98 1.56-1.56c.68-.69 1.5-1.03 2.47-1.03.97 0 1.8.34 2.48 1.02l1.3 1.32a3.48 3.48 0 0 1 1 2.48c0 .58-.11 1.11-.37 1.6l-.02.02v.02l-.02.04c-.14.27-.35.54-.6.8L16.23 15l-.01.02-.01.02c-.44.42-.92.7-1.43.83a4.55 4.55 0 0 0 1.23-3.52L18 10.38c.18-.21.3-.42.35-.65a2.03 2.03 0 0 0-.01-.9 1.96 1.96 0 0 0-.36-.58l-1.3-1.3a1.49 1.49 0 0 0-1.06-.42c-.42 0-.77.14-1.06.4l-1.2 1.27-.8.8-1.16 1.15c-.08.08-.18.21-.29.4a1.66 1.66 0 0 0-.08 1.12l.02.03v.02l.06.14s.01.03.05.06l.06.13.02.02.01.02.01.02c.05.08.1.13.14.16l.47.5c0 .04-.02.09-.04.15l-.06.12-1.15 1.15-.1.08-.56-.56a2.3 2.3 0 0 0-.18-.19c-.02-.01-.02-.03-.02-.04l-.02-.02a.37.37 0 0 1-.1-.12c-.03-.03-.05-.04-.05-.06l-.1-.15-.02-.02-.02-.04-.08-.17v-.02a5.1 5.1 0 0 1-.28-.69 1.03 1.03 0 0 1-.04-.26c-.06-.23-.1-.46-.1-.7v.01z" fill="#A8A8A8" fill-rule="evenodd"></path></svg></span></button></div></div></div></div></header><span class="l"></span><section><div><div class="ha as kg kh ki kj"></div><div class="kk kl km kn ko"><div class=""><h1 class="pw-post-title kp kq kr bm ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln gl" id="eae2">Machine Learning in Production</h1></div><div class=""><h2 class="pw-subtitle-paragraph lo kq kr bm b lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf cn" id="0bb3">Machine Learning Models beyond Jupyter-Notebooks.</h2></div><figure class="mh mi mj mk ix ml il im paragraph-image"><div class="mm mn do mo ce mp" role="button" tabindex="0"><div class="il im mg"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*NFqdCCgSI4wD1nK9OxEx3Q.png 640w, https://miro.medium.com/max/720/1*NFqdCCgSI4wD1nK9OxEx3Q.png 720w, https://miro.medium.com/max/750/1*NFqdCCgSI4wD1nK9OxEx3Q.png 750w, https://miro.medium.com/max/786/1*NFqdCCgSI4wD1nK9OxEx3Q.png 786w, https://miro.medium.com/max/828/1*NFqdCCgSI4wD1nK9OxEx3Q.png 828w, https://miro.medium.com/max/1100/1*NFqdCCgSI4wD1nK9OxEx3Q.png 1100w, https://miro.medium.com/max/1400/1*NFqdCCgSI4wD1nK9OxEx3Q.png 1400w"/><img alt="" class="ce mq mr c" height="630" loading="eager" role="presentation" width="700"/></picture></div></div><figcaption class="ms bl in il im mt mu bm b bn bo cn">Screenshot of <a class="au mv" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank">MNIST-Database</a> plotted by the Author</figcaption></figure><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="caba">This article focuses on deploying machine learning models using mnist handwritten digit recognition as a base example implemented in <a class="au mv" href="https://www.tensorflow.org/overview/" rel="noopener ugc nofollow" target="_blank">tensorflow-2</a>. In the end, we will be cooking up a small web app in <a class="au mv" href="https://reactjs.org/" rel="noopener ugc nofollow" target="_blank">React</a> to test our model. If you are a machine learning enthusiast then you already know that mnist digit recognition is the hello world program of deep learning and by far you have already seen way too many articles about digit-recognition on medium and probably implemented that already which is exactly why I won’t be focusing too much on the problem itself and instead show you how you can deploy your models and consume them in production. To see the end result you can view the deployed-app <a class="au mv" href="http://asjadanis.github.io/tfjs-digit-demo" rel="noopener ugc nofollow" target="_blank">here</a></p><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="e8bf">Before jumping into deployments I will quickly give you a brief walkthrough of the model and show you how you can save your model and consume it in production later on. If you are tired of reading about handwritten-digit-recognition like me you can skip this portion and use the <a class="au mv" href="https://github.com/asjadanis/mnist-digit-recog" rel="noopener ugc nofollow" target="_blank">github-repo</a> to get the model so you can follow the rest of the guide.</p><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="7912"><strong class="my ks">Libraries used.</strong></p><ul class=""><li class="ns nt kr my b mz na nc nd nf nu nj nv nn nw nr nx ny nz oa gl" id="7667">Tensorflow 2</li><li class="ns nt kr my b mz ob nc oc nf od nj oe nn of nr nx ny nz oa gl" id="a33b">Matplotlip</li><li class="ns nt kr my b mz ob nc oc nf od nj oe nn of nr nx ny nz oa gl" id="254a">Numpy</li></ul><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="0899">For pre-processing the data I am just normalizing the pixel values in 0–1 range by dividing with 255.</p><figure class="mh mi mj mk ix ml"><div class="m ht l do"><div class="og oh l"></div></div></figure><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="cab1">Once we have the data loaded and pre-processed I am using a convolutional-net with 2 conv-layers each followed by a max-pooling layer which is then flattened before it’s passed on to a dense layer with 128 units and finally our output layer has 10-units and its using <a class="au mv" href="https://medium.com/data-science-bootcamp/understand-the-softmax-function-in-minutes-f3a59641e86d" rel="noopener">softmax</a> as the activation function which turns the end result to probabilities and distributes it over our classes.</p><figure class="mh mi mj mk ix ml"><div class="m ht l do"><div class="og oh l"></div></div></figure><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="91eb">For training the model I am using <a class="au mv" href="https://www.tensorflow.org/tensorboard" rel="noopener ugc nofollow" target="_blank">tensorboard</a>, early-stopping, and model-checkpoint callbacks for gathering information during the training process. Tensorboard is a very handy tool in the tensorflow ecosystem, it lets you visualize your training process, model-graphs, and provides useful metrics that help you a lot in representing and sharing your findings and quickly experiment. <a class="au mv" href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping" rel="noopener ugc nofollow" target="_blank">Early-Stopping</a> is also a very useful call-back that lets you monitor a very specific metric and stops training if that metric is not improving over time. This saves us from <a class="au mv" href="https://www.kdnuggets.com/2019/12/5-techniques-prevent-overfitting-neural-networks.html" rel="noopener ugc nofollow" target="_blank">over-fitting</a> our model.</p><figure class="mh mi mj mk ix ml"><div class="m ht l do"><div class="og oh l"></div></div></figure><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="2df8">Now that we have trained the model we will save our model in protobuf format which is the default-format in tensorflow-2. Note that we are saving the model in a sub-folder named 1. The reason is that tensorflow-serving uses this convention to load the model version you specify. By default, the server will serve the model with the largest version number.</p><figure class="mh mi mj mk ix ml"><div class="m ht l do"><div class="og oh l"></div></div></figure><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="e5f8">The last part would be to convert our model to work with tensorflow-js in the browser and for that purpose, we will use <a class="au mv" href="https://github.com/tensorflow/tfjs/tree/master/tfjs-converter" rel="noopener ugc nofollow" target="_blank">tensorflow-converter</a> which helps us convert our pre-trained tensorflow models in python to work in the browser using tensorflow-js. Install and run the tool using the below command and provide the path to your saved model directory when the wizard asks.</p><pre class="mh mi mj mk ix oi bs oj ok dz ol"><span class="gl om on kr ol b dm oo op l oq or" id="f509">pip install tensorflowjs[wizard]<br/>tensorflowjs_wizard</span></pre><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="a449">If you have followed all the steps till here and have been successfully able to save a model congratulations you are halfway through the journey. Now you have a model that you can deploy in the cloud and use from various applications.</p></div><div class="o dx os ot jv ou" role="separator"><span class="ov gx ci ow ox oy"></span><span class="ov gx ci ow ox oy"></span><span class="ov gx ci ow ox"></span></div><div class="kk kl km kn ko"><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="89ad">Before we begin with the deployments part lets quickly go through an alternative approach which is also widely used and implemented via a Flask app or an express-server or any other api-framework to serve the model which is not a very efficient way of serving your models in production, the reason being that those frameworks are primarily designed for HTTP requests/response and do not account for your machine’s hardware capability when making inferences. Similarly, it could be hard to standardize the way you load and serve your model via a rest end-point and when you have multiple models/projects being worked on. One of the biggest advantage of using tensorflow-serving over Flask is that it is primarily built for serving flexible and scalable ML models in production and has been battle-tested. Plus it has support for model versioning and serving many models with many versions and it scales really well. However, Flask or any other API-framework that you use can come in very handy if they are used as a middle layer between the client and tensorflow-serving, handling the routing for different tf-servers and preprocessing the data before sending it over to the model for prediction. You can visit this <a class="au mv" href="/deploying-keras-models-using-tensorflow-serving-and-flask-508ba00f1037" rel="noopener" target="_blank">article</a> for a much better understanding of this.</p><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="b2a5">Now we can get on with the deployment part, I will be using Google Cloud to deploy the models and go step by step into the various cloud services that are available to you. Google cloud and tensorflow integrate quite well, we will be looking in particular at these three options that are available to us.</p><ul class=""><li class="ns nt kr my b mz na nc nd nf nu nj nv nn nw nr nx ny nz oa gl" id="929e"><a class="au mv" href="https://www.tensorflow.org/tfx/guide/serving" rel="noopener ugc nofollow" target="_blank">Tensorflow-Serving</a>.</li><li class="ns nt kr my b mz ob nc oc nf od nj oe nn of nr nx ny nz oa gl" id="7f8c"><a class="au mv" href="https://cloud.google.com/ai-platform" rel="noopener ugc nofollow" target="_blank">AI-Platform-Predictions</a></li><li class="ns nt kr my b mz ob nc oc nf od nj oe nn of nr nx ny nz oa gl" id="aa09"><a class="au mv" href="https://cloud.google.com/functions#:~:text=Cloud%20Functions%20allows%20you%20to%20trigger%20your%20code%20from%20Google,or%20backend%20application%20via%20HTTP.&amp;text=what%20you%20use-,You%20are%20only%20billed%20for%20your%20function's%20execution%20time,to%20the%20nearest%20100%20milliseconds." rel="noopener ugc nofollow" target="_blank">Cloud-Functions</a></li></ul><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="d96f">In the first part of this series, we will be using tensorflow-serving, followed by AI-Platform and cloud functions in the next two parts.</p><h2 class="om on kr bm oz pa pb fe pc pd pe fg pf nf pg ph pi nj pj pk pl nn pm pn po pp gl" id="9d66">Tensorflow Serving</h2><p class="pw-post-body-paragraph mw mx kr my b mz pq ls nb nc pr lv ne nf ps nh ni nj pt nl nm nn pu np nq nr kk gl" id="201e">Tensorflow serving is a part of the tensorflow extended ecosystem, one of the key benefits of tensorflow serving is that it’s highly scalable and has low latency. Tensorflow serving has the capability to serve multiple models and versions which is a potential use-case when you are going in production you might need to update your models and serve multiple versions.</p><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="c289">We will be using tensorflow-serving with docker which is very easy and quick to get started with. Before following the next steps head over to the <a class="au mv" href="https://www.docker.com/get-started" rel="noopener ugc nofollow" target="_blank">docker-website</a> and install the docker-desktop app for your OS.</p><pre class="mh mi mj mk ix oi bs oj ok dz ol"><span class="gl om on kr ol b dm oo op l oq or" id="7496">// from terminal pull the tensorflow-serving docker image                       docker pull tensorflow/serving</span></pre><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="c746">The tensorflow serving image has port 8500 exposed for <a class="au mv" href="https://grpc.io/" rel="noopener ugc nofollow" target="_blank">gRPC</a> whereas port 8501 is exposed for REST-API. Now to serve with docker we need</p><ul class=""><li class="ns nt kr my b mz na nc nd nf nu nj nv nn nw nr nx ny nz oa gl" id="5bb7">A saved-model that we want to serve. (We have already saved our model)</li><li class="ns nt kr my b mz ob nc oc nf od nj oe nn of nr nx ny nz oa gl" id="ba52">We need to open up a port on our host on which we will be serving the model.</li><li class="ns nt kr my b mz ob nc oc nf od nj oe nn of nr nx ny nz oa gl" id="7470">A name for our model which the client applications will use to refer to the model.</li></ul><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="0fd0">Next in the terminal run the below com</p><pre class="mh mi mj mk ix oi bs oj ok dz ol"><span class="gl om on kr ol b dm oo op l oq or" id="7e7f">docker run -p 8501:8501 --mount type=bind,source=&lt;path-to-your-model&gt;,target=/models/mnist-digit-model -e MODEL_NAME=mnist-digit-recog -t tensorflow/serving</span></pre><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="8939">Please note the path would be to the <strong class="my ks">root</strong> <strong class="my ks">folder</strong> of your model and not the sub-folder which specifies the model-version. With the above command, we have basically started a docker container and binded the rest-api port with the host port <em class="pv">8501</em>. Next, we are bounding our saved model path to the default model path i.e models/<em class="pv">mnist-digit-recog</em>. After which we have specified the environment variable name and set it to <em class="pv">mnist-digit-recog </em>and that is it, if you have followed the steps till here properly you should have a docker image running with tensorflow-serving and your model being served on port 8501.</p><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="afb7"><em class="pv">Note if you want to expose the gRPC port too you can run the below command.</em></p><pre class="mh mi mj mk ix oi bs oj ok dz ol"><span class="gl om on kr ol b dm oo op l oq or" id="1fe2">docker run -p 8501:8501 -p 8500:8500 --mount type=bind,source=&lt;path-to-your-model&gt;,target=/models/mnist-digit-model -e MODEL_NAME=mnist-digit-recog -t tensorflow/serving</span></pre><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="95e2">If everything ran successfully you should have similar output on your terminal as below.</p><figure class="mh mi mj mk ix ml il im paragraph-image"><div class="mm mn do mo ce mp" role="button" tabindex="0"><div class="il im pw"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*zgaqH37KG-ONdA7ms0KAWQ.png 640w, https://miro.medium.com/max/720/1*zgaqH37KG-ONdA7ms0KAWQ.png 720w, https://miro.medium.com/max/750/1*zgaqH37KG-ONdA7ms0KAWQ.png 750w, https://miro.medium.com/max/786/1*zgaqH37KG-ONdA7ms0KAWQ.png 786w, https://miro.medium.com/max/828/1*zgaqH37KG-ONdA7ms0KAWQ.png 828w, https://miro.medium.com/max/1100/1*zgaqH37KG-ONdA7ms0KAWQ.png 1100w, https://miro.medium.com/max/1400/1*zgaqH37KG-ONdA7ms0KAWQ.png 1400w"/><img alt="" class="ce mq mr c" height="184" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="ms bl in il im mt mu bm b bn bo cn">Screenshot of terminal by the Author</figcaption></figure><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="45f0">If you want to explore tensorflow-serving with docker I suggest you look into the <a class="au mv" href="https://www.tensorflow.org/tfx/serving/docker" rel="noopener ugc nofollow" target="_blank">official docs</a>.</p><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="16d1">Now that we have tensorflow serving our model, let’s quickly test this by making a post request, and verify that everything is working correctly.</p><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="ae70">The REST url structure is given below:</p><pre class="mh mi mj mk ix oi bs oj ok dz ol"><span class="gl om on kr ol b dm oo op l oq or" id="4209">HOST = localhost<br/>PORT = 8501<br/>MODEL_NAME = mnist-digit-recog<br/>MODEL_VERSION = 1</span><span class="gl om on kr ol b dm px op l oq or" id="fcfa">// Default<br/>http://{HOST}:{PORT}/v1/models/{MODEL_NAME}:predict</span><span class="gl om on kr ol b dm px op l oq or" id="7ca2">// Specific Model-Version<br/>http://{HOST}:{PORT}/v1/models/{MODEL_NAME}/versions/{MODEL_VERSION}:predict</span></pre><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="e736">We can use the below piece of code to quickly test that the model is being served properly. Load up the notebook from the attached github-repo above and in a new cell paste the code below and run it to see the results.</p><figure class="mh mi mj mk ix ml"><div class="m ht l do"><div class="og oh l"></div></div></figure><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="bec0">Similarly, you can now call this end-point from any client-side application and voila you should have the predicted digit. For instance, if you are a JS fan you can use the below code snippet.</p><figure class="mh mi mj mk ix ml"><div class="m ht l do"><div class="og oh l"></div></div></figure><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="6fbd">Awesome now if we want to create our own docker-image that has our model built-in we can do that by first running the serving image as a daemon and then copy our saved model to the containers model folder. For that quickly follow the steps from the official tensorflow-serving guide <a class="au mv" href="https://www.tensorflow.org/tfx/serving/docker#creating_your_own_serving_image" rel="noopener ugc nofollow" target="_blank">here</a>. You can name your container whatever you want, I have called mine <strong class="my ks"><em class="pv">mnist-digit-container </em></strong>and now we don’t have to bind our model path or do any extra config. We can just run the below command to get our model served.</p><pre class="mh mi mj mk ix oi bs oj ok dz ol"><span class="gl om on kr ol b dm oo op l oq or" id="1e90">docker run -p 8501:8501 &lt;your-container-name&gt;</span></pre><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="f9cd">And that’s it we have a container with our model built-in. Before we move on to the next step please give this <a class="au mv" href="https://www.tensorflow.org/tfx/serving/serving_config" rel="noopener ugc nofollow" target="_blank">link</a> a visit which discusses how you can specify the model configuration and versioning which could be very handy.</p><h2 class="om on kr bm oz pa pb fe pc pd pe fg pf nf pg ph pi nj pj pk pl nn pm pn po pp gl" id="5648">Deployment on GCP</h2><p class="pw-post-body-paragraph mw mx kr my b mz pq ls nb nc pr lv ne nf ps nh ni nj pt nl nm nn pu np nq nr kk gl" id="7c25">Now we will deploy the docker image on Google Cloud using Kubernetes. Before we move on with the setup let’s first have a quick glance at Kubernetes. In short, Kubernetes helps automate the process of deploying, scaling, and managing containerized applications. In a production environment, it is needed to manage the containers and make sure that they are always up and available and there is no downtime, this is where Kubernetes comes into play and help scale your containarized apps. It can offer load-balancing, self-healing, resource utilization in the best possible way. Do give the official <a class="au mv" href="https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/" rel="noopener ugc nofollow" target="_blank">Kubernetes docs</a> a visit to get a deeper understanding of how it works.</p><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="9457">When you deploy Kubernetes you get a cluster and every cluster will have at least one worker node.</p><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="c2df">A few terminologies to keep in mind when using Kubernetes.</p><ul class=""><li class="ns nt kr my b mz na nc nd nf nu nj nv nn nw nr nx ny nz oa gl" id="72e4"><a class="au mv" href="https://kubernetes.io/docs/concepts/architecture/nodes/" rel="noopener ugc nofollow" target="_blank"><strong class="my ks">Node</strong></a><strong class="my ks"> — </strong>A node is basically a worker machine that runs a containerized app.</li><li class="ns nt kr my b mz ob nc oc nf od nj oe nn of nr nx ny nz oa gl" id="d4dd"><a class="au mv" href="https://kubernetes.io/docs/concepts/workloads/pods/" rel="noopener ugc nofollow" target="_blank"><strong class="my ks">POD</strong></a><strong class="my ks"> — </strong>The worker nodes host POD’s and a POD is a group of one or more containers, where each POD has a unique IP-address and a namespace.</li><li class="ns nt kr my b mz ob nc oc nf od nj oe nn of nr nx ny nz oa gl" id="0603"><strong class="my ks">YAML — </strong>A file for configuring Kubernetes.</li><li class="ns nt kr my b mz ob nc oc nf od nj oe nn of nr nx ny nz oa gl" id="82ed"><a class="au mv" href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/" rel="noopener ugc nofollow" target="_blank"><strong class="my ks">Deployment</strong></a><strong class="my ks"> — </strong>Specify the number of replicas of a POD you want to run. Deployment ensures then that the replicas are up and running in the cluster.</li><li class="ns nt kr my b mz ob nc oc nf od nj oe nn of nr nx ny nz oa gl" id="40c7"><a class="au mv" href="https://kubernetes.io/docs/concepts/services-networking/service/" rel="noopener ugc nofollow" target="_blank"><strong class="my ks">Service</strong></a><strong class="my ks"> — </strong>An abstraction to define a policy on how to access the POD’s, which is connected to the deployment.</li></ul><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="5034">For this, you first need to set up an account on Google Cloud. Once you have an account set up, install the google-sdk from <a class="au mv" href="https://cloud.google.com/sdk/docs/install" rel="noopener ugc nofollow" target="_blank">this</a> link. Next head over to Google Cloud Console and create a new project I have called mine <em class="pv">tensorflow-training</em>.</p><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="6006">Now head over to the terminal and run <code class="hb py pz qa ol b">gcloud init</code> this will ask you a couple of straight-forward questions and once you are done with this you will be authenticated with your google cloud account.</p><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="79bf">Next, run <code class="hb py pz qa ol b">gcloud config set project [your-project-id]</code> to set the project you just created above. To get the project id you can go to the <a class="au mv" href="https://console.cloud.google.com/" rel="noopener ugc nofollow" target="_blank">gcp console</a> and from the dropdown next to the search bar you can select the project-id.</p><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="6187">Now we are all ready and set-up to create a Kubernetes Engine for the service deployment. For this follow the below steps.</p><ul class=""><li class="ns nt kr my b mz na nc nd nf nu nj nv nn nw nr nx ny nz oa gl" id="2642">Enable the Kubernetes Engine Api in cloud console by going into API &amp; Services -&gt; Enable API -&gt; Kubernetes Engine Api</li><li class="ns nt kr my b mz ob nc oc nf od nj oe nn of nr nx ny nz oa gl" id="502d"><code class="hb py pz qa ol b">gcloud container clusters create mnist-digit-cluster — num-nodes 2 --zone &lt;specify-the-zone&gt;</code></li><li class="ns nt kr my b mz ob nc oc nf od nj oe nn of nr nx ny nz oa gl" id="9bcd">Next we will set the default cluster for gcloud container command by running <code class="hb py pz qa ol b">gcloud config set container/cluster mnist-digit-cluster</code></li><li class="ns nt kr my b mz ob nc oc nf od nj oe nn of nr nx ny nz oa gl" id="8972">Now we will pass cluster credentials to kubectl <code class="hb py pz qa ol b">gcloud container clusters get-credentials mnist-digit-cluster —- zone &lt;specify-the-zone&gt;</code></li></ul><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="dfb5">After this, we will upload our docker image to the Google Container Registry so that we are able to run it on the GCP.</p><ul class=""><li class="ns nt kr my b mz na nc nd nf nu nj nv nn nw nr nx ny nz oa gl" id="00a3">First we will tag our image using Container Registry format and our project name by running <code class="hb py pz qa ol b">docker tag &lt;container-name&gt; gcr.io/&lt;project-id&gt;/&lt;image-name&gt;</code></li><li class="ns nt kr my b mz ob nc oc nf od nj oe nn of nr nx ny nz oa gl" id="bc33"><em class="pv">Note the image-name above can be different from the image name on the local-machine.</em></li><li class="ns nt kr my b mz ob nc oc nf od nj oe nn of nr nx ny nz oa gl" id="dbdf">Next we configure docker to use gcloud as credential-helper by running <code class="hb py pz qa ol b">gcloud auth configure-docker</code></li><li class="ns nt kr my b mz ob nc oc nf od nj oe nn of nr nx ny nz oa gl" id="9d4b">Now we are all set to push our docker image to the registry. <code class="hb py pz qa ol b">docker push gcr.io/&lt;project-id&gt;/&lt;image-name</code></li></ul><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="e332">We are almost there, now we need to create a <strong class="my ks">yaml</strong> config file for creating a deployment, so head into your favorite text editor and paste the following content in a file and save on your local-disk with <strong class="my ks"><em class="pv">.yaml </em></strong>extension. Please update the yaml file with your <code class="hb py pz qa ol b">project-id</code> and <code class="hb py pz qa ol b">image-name</code> and I also suggest that you look into the available options for configuring.</p><pre class="mh mi mj mk ix oi bs oj ok dz ol"><span class="gl om on kr ol b dm oo op l oq or" id="92fd">apiVersion: apps/v1<br/>kind: Deployment<br/>metadata:<br/>  name: mnist-deployment<br/>spec:<br/>  replicas: 3<br/>  selector:<br/>    matchLabels:<br/>      app: mnist-server<br/>  template:<br/>    metadata:<br/>      labels:<br/>        app: mnist-server<br/>    spec:<br/>      containers:<br/>      - name: &lt;image-name&gt;<br/>        image: gcr.io/&lt;project-id&gt;/&lt;image-name&gt;<br/>        ports:<br/>        - containerPort: 8501<br/>---<br/>apiVersion: v1<br/>kind: Service<br/>metadata:<br/>  labels:<br/>    run: mnist-service<br/>  name: mnist-service<br/>spec:<br/>  ports:<br/>  - port: 8501<br/>    targetPort: 8501<br/>  selector:<br/>    app: mnist-server<br/>  type: LoadBalancer</span></pre><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="7e54">Now you can run <code class="hb py pz qa ol b">kubectl create -f &lt;path-to-yaml-file&gt;</code> and if everything goes well you should be notified that both deployment and service were created. You can verify this by running the below commands in terminal</p><ul class=""><li class="ns nt kr my b mz na nc nd nf nu nj nv nn nw nr nx ny nz oa gl" id="5270"><code class="hb py pz qa ol b">kubectl get deployments</code></li><li class="ns nt kr my b mz ob nc oc nf od nj oe nn of nr nx ny nz oa gl" id="2a17"><code class="hb py pz qa ol b">kubectl get services</code></li></ul><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="9b0b">And now finally we can describe our service using <code class="hb py pz qa ol b">kubectl describe service mnist-service</code> note down the external ip-address listed next to LoadBalancer Ingress. This is the IP we can now use to query our deployed model from client applications.</p><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="49c9">The URL structure will be the same as above you just have to replace <strong class="my ks">localhost </strong>with the above ip-address and that’s it. To quickly verify you can use the above python or js code-snippet to predict or just go to the below URL in the browser to make sure it all went well.</p><pre class="mh mi mj mk ix oi bs oj ok dz ol"><span class="gl om on kr ol b dm oo op l oq or" id="11eb">url = http://{ip}:8501/v1/models/&lt;your-model-name&gt;/versions/1</span></pre><figure class="mh mi mj mk ix ml il im paragraph-image"><div class="mm mn do mo ce mp" role="button" tabindex="0"><div class="il im qb"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*OPA6GIj_6k0u2ZZcM6XzTA.png 640w, https://miro.medium.com/max/720/1*OPA6GIj_6k0u2ZZcM6XzTA.png 720w, https://miro.medium.com/max/750/1*OPA6GIj_6k0u2ZZcM6XzTA.png 750w, https://miro.medium.com/max/786/1*OPA6GIj_6k0u2ZZcM6XzTA.png 786w, https://miro.medium.com/max/828/1*OPA6GIj_6k0u2ZZcM6XzTA.png 828w, https://miro.medium.com/max/1100/1*OPA6GIj_6k0u2ZZcM6XzTA.png 1100w, https://miro.medium.com/max/1400/1*OPA6GIj_6k0u2ZZcM6XzTA.png 1400w"/><img alt="" class="ce mq mr c" height="354" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="ms bl in il im mt mu bm b bn bo cn">Screenshot by the Author</figcaption></figure><h2 class="om on kr bm oz pa pb fe pc pd pe fg pf nf pg ph pi nj pj pk pl nn pm pn po pp gl" id="b38a">TF-JS Model</h2><p class="pw-post-body-paragraph mw mx kr my b mz pq ls nb nc pr lv ne nf ps nh ni nj pt nl nm nn pu np nq nr kk gl" id="afd3">Now it’s time to host our converted tensorflow model in a cloud-storage bucket and load it in React-App using <a class="au mv" href="https://www.tensorflow.org/js" rel="noopener ugc nofollow" target="_blank">Tensorflow-JS</a>. For this quickly head over to your google cloud console and navigate to storage. Create a bucket choose a name, and specify the location. Once the bucket is created you can either upload your tf-js model from the UI or from the command line by running the below command in the terminal.</p><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="ed72">Make sure that you have the converted <strong class="my ks">model.json</strong> file and the companion <strong class="my ks">group1-shard.bin</strong> file.</p><pre class="mh mi mj mk ix oi bs oj ok dz ol"><span class="gl om on kr ol b dm oo op l oq or" id="f7ae">gsutil cp -r &lt;path-to-tf-js-model-dir&gt; gs://&lt;bucket-name&gt;/</span></pre><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="bd70">Now that we have uploaded the model json file in the bucket we need to make the files public to be accessible for the client-apps and enable cors on the created bucket. For cors please read <a class="au mv" href="https://cloud.google.com/storage/docs/cross-origin" rel="noopener ugc nofollow" target="_blank">here</a> for a detailed explanation.</p><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="e310">Make the files public by navigating to the files in the bucket and click <strong class="my ks">Edit Permissions</strong> where you can add an entry for <strong class="my ks">Public</strong>. Do this for both <code class="hb py pz qa ol b">model.json</code> &amp; <code class="hb py pz qa ol b">group1-shard1of1.bin</code> file. Once marked public, copy the public-url for model.json file which will be needed for loading the model.</p><figure class="mh mi mj mk ix ml il im paragraph-image"><div class="mm mn do mo ce mp" role="button" tabindex="0"><div class="il im qc"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*BNsYC9jN0aOgBGGPKpSASg.png 640w, https://miro.medium.com/max/720/1*BNsYC9jN0aOgBGGPKpSASg.png 720w, https://miro.medium.com/max/750/1*BNsYC9jN0aOgBGGPKpSASg.png 750w, https://miro.medium.com/max/786/1*BNsYC9jN0aOgBGGPKpSASg.png 786w, https://miro.medium.com/max/828/1*BNsYC9jN0aOgBGGPKpSASg.png 828w, https://miro.medium.com/max/1100/1*BNsYC9jN0aOgBGGPKpSASg.png 1100w, https://miro.medium.com/max/1400/1*BNsYC9jN0aOgBGGPKpSASg.png 1400w"/><img alt="" class="ce mq mr c" height="43" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="ms bl in il im mt mu bm b bn bo cn">Screenshot of <a class="au mv" href="https://console.cloud.google.com/" rel="noopener ugc nofollow" target="_blank">Google Cloud Platform</a> by the Author</figcaption></figure><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="2bfb">For enabling cors on the bucket head over to google console and active Google Cloud Shell.</p><figure class="mh mi mj mk ix ml il im paragraph-image"><div class="mm mn do mo ce mp" role="button" tabindex="0"><div class="il im qd"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/1*PDt-5LfOpLGUdWH4EyN1mA.png 640w, https://miro.medium.com/max/720/1*PDt-5LfOpLGUdWH4EyN1mA.png 720w, https://miro.medium.com/max/750/1*PDt-5LfOpLGUdWH4EyN1mA.png 750w, https://miro.medium.com/max/786/1*PDt-5LfOpLGUdWH4EyN1mA.png 786w, https://miro.medium.com/max/828/1*PDt-5LfOpLGUdWH4EyN1mA.png 828w, https://miro.medium.com/max/1100/1*PDt-5LfOpLGUdWH4EyN1mA.png 1100w, https://miro.medium.com/max/1400/1*PDt-5LfOpLGUdWH4EyN1mA.png 1400w"/><img alt="" class="ce mq mr c" height="65" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="ms bl in il im mt mu bm b bn bo cn">Screenshot of <a class="au mv" href="https://console.cloud.google.com/" rel="noopener ugc nofollow" target="_blank">Google Cloud Platform</a> by the Author</figcaption></figure><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="f176">Once you are in the shell type</p><pre class="mh mi mj mk ix oi bs oj ok dz ol"><span class="gl om on kr ol b dm oo op l oq or" id="5a90">//Allowing every domain to access your bucket.</span><span class="gl om on kr ol b dm px op l oq or" id="bd77">echo '[{"origin": ["*"],"responseHeader": ["Content-Type"],"method": ["GET", "HEAD"],"maxAgeSeconds": 3600}]' &gt; cors-config.json</span><span class="gl om on kr ol b dm px op l oq or" id="3bf0">gsutil cors set cors-config.json gs://&lt;bucket-name&gt;</span></pre><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="9e3f">Now we are all set to load the model in our client-app using tensorflow-js.</p><figure class="mh mi mj mk ix ml"><div class="m ht l do"><div class="og oh l"></div></div></figure><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="9438">To explore the source-code head over to the <a class="au mv" href="https://github.com/asjadanis/tfjs-digit-demo" rel="noopener ugc nofollow" target="_blank">github-repo</a>.</p><div class="qe qf it iv qg qh"><a href="https://github.com/asjadanis/tfjs-digit-demo" rel="noopener ugc nofollow" target="_blank"><div class="qi o hs"><div class="qj o da dx en qk"><h2 class="bm ks dm bo ht ql hv hw qm hy ia kq gl">asjadanis/tfjs-digit-demo</h2><div class="qn l"><h3 class="bm b dm bo ht ql hv hw qm hy ia cn">A client side demo application for single-digit recognition using tensorflow-js in the browser in a React app. Note…</h3></div><div class="qo l"><p class="bm b fc bo ht ql hv hw qm hy ia cn">github.com</p></div></div><div class="qp l"><div class="qq l qr qs qt qp qu mq qh"></div></div></div></a></div><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="1b7e">Here’s our deployed model in action.</p><figure class="mh mi mj mk ix ml"><div class="m ht l do"><div class="qv oh l"></div></div><figcaption class="ms bl in il im mt mu bm b bn bo cn">GIF by the Author</figcaption></figure><p class="pw-post-body-paragraph mw mx kr my b mz na ls nb nc nd lv ne nf ng nh ni nj nk nl nm nn no np nq nr kk gl" id="c898">Happy Coding.</p></div></div></section></div></div></article>