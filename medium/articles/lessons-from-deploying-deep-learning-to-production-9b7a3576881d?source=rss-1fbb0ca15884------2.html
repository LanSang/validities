<article><div class="l"><div class="gg gh gi gj gk gl gm ce gn ch l"></div><div class="l"><header class="pw-post-byline-header go gp gq gr gs gt gu gv gw gx l"><div class="o gy u"><div class="o"><div class="fj l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="/@pgao?source=post_page-----9b7a3576881d--------------------------------" rel="noopener follow"><div class="l do"><img alt="Peter Gao" class="l ch fl gz ha fp" height="48" loading="lazy" src="https://miro.medium.com/fit/c/96/96/1*pchG7itXQE_EufIjMsprng.jpeg" width="48"/><div class="fk fl l gz ha fo aq"></div></div></a></div><div class="l"><div class="pw-author bm b dm dn ga"><div class="hb o hc"><div><div aria-hidden="false" class="ci"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="/@pgao?source=post_page-----9b7a3576881d--------------------------------" rel="noopener follow">Peter Gao</a></div></div><div class="hd he hf hg hh d"><span><button class="bm b hi bo hj hk hl hm hn ho hp bd bz hq hr hs cd cf cg ch ci cj">Follow</button></span></div></div></div><div class="o ao ht"><p class="pw-published-date bm b bn bo cn"><span>Apr 5</span></p><div aria-hidden="true" class="hu ci"><span aria-hidden="true" class="l"><span class="bm b bn bo cn">·</span></span></div><div class="pw-reading-time bm b bn bo cn">12 min read</div></div></div></div><div class="o ao"><div class="h k hv hw hx"><div class="hy l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on twitter" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M20 5.34c-.67.41-1.4.7-2.18.87a3.45 3.45 0 0 0-5.02-.1 3.49 3.49 0 0 0-1.02 2.47c0 .28.03.54.07.8a9.91 9.91 0 0 1-7.17-3.66 3.9 3.9 0 0 0-.5 1.74 3.6 3.6 0 0 0 1.56 2.92 3.36 3.36 0 0 1-1.55-.44V10c0 1.67 1.2 3.08 2.8 3.42-.3.06-.6.1-.94.12l-.62-.06a3.5 3.5 0 0 0 3.24 2.43 7.34 7.34 0 0 1-4.36 1.49l-.81-.05a9.96 9.96 0 0 0 5.36 1.56c6.4 0 9.91-5.32 9.9-9.9v-.5c.69-.49 1.28-1.1 1.74-1.81-.63.3-1.3.48-2 .56A3.33 3.33 0 0 0 20 5.33" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="hy l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on facebook" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 12.04c0-4.3-3.47-7.79-7.75-7.79a7.77 7.77 0 0 0-5.9 12.84 7.77 7.77 0 0 0 4.69 2.63v-5.49h-1.9v-2.2h1.9v-1.62c0-1.88 1.14-2.9 2.8-2.9.8 0 1.49.06 1.69.08v1.97h-1.15c-.91 0-1.1.43-1.1 1.07v1.4h2.17l-.28 2.2h-1.88v5.52a7.77 7.77 0 0 0 6.7-7.71" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="hy l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on linkedin" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 5.39v13.22a1.14 1.14 0 0 1-1.14 1.14H5.39a1.14 1.14 0 0 1-1.14-1.14V5.39a1.14 1.14 0 0 1 1.14-1.14h13.22a1.14 1.14 0 0 1 1.14 1.14zM8.81 10.18H6.53v7.3H8.8v-7.3zM9 7.67a1.31 1.31 0 0 0-1.3-1.32h-.04a1.32 1.32 0 0 0 0 2.64A1.31 1.31 0 0 0 9 7.71v-.04zm8.46 5.37c0-2.2-1.4-3.05-2.78-3.05a2.6 2.6 0 0 0-2.3 1.18h-.07v-1h-2.14v7.3h2.28V13.6a1.51 1.51 0 0 1 1.36-1.63h.09c.72 0 1.26.45 1.26 1.6v3.91h2.28l.02-4.43z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="l fr"><div><div aria-hidden="false" class="ci"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path clip-rule="evenodd" d="M3.57 14.67c0-.57.13-1.11.38-1.6l.02-.02v-.02l.02-.02c0-.02 0-.02.02-.02.12-.26.3-.52.57-.8L7.78 9v-.02l.01-.02c.44-.41.91-.7 1.44-.85a4.87 4.87 0 0 0-1.19 2.36A5.04 5.04 0 0 0 8 11.6L6.04 13.6c-.19.19-.32.4-.38.65a2 2 0 0 0 0 .9c.08.2.2.4.38.57l1.29 1.31c.27.28.62.42 1.03.42.42 0 .78-.14 1.06-.42l1.23-1.25.79-.78 1.15-1.16c.08-.09.19-.22.28-.4.1-.2.15-.42.15-.67 0-.16-.02-.3-.06-.45l-.02-.02v-.02l-.07-.14s0-.03-.04-.06l-.06-.13-.02-.02c0-.02 0-.03-.02-.05a.6.6 0 0 0-.14-.16l-.48-.5c0-.04.02-.1.04-.15l.06-.12 1.17-1.14.09-.09.56.57c.02.04.08.1.16.18l.05.04.03.06.04.05.03.04.04.06.1.14.02.02c0 .02.01.03.03.04l.1.2v.02c.1.16.2.38.3.68a1 1 0 0 1 .04.25 3.2 3.2 0 0 1 .02 1.33 3.49 3.49 0 0 1-.95 1.87l-.66.67-.97.97-1.56 1.57a3.4 3.4 0 0 1-2.47 1.02c-.97 0-1.8-.34-2.49-1.03l-1.3-1.3a3.55 3.55 0 0 1-1-2.51v-.01h-.02v.02zm5.39-3.43c0-.19.02-.4.07-.63.13-.74.44-1.37.95-1.87l.66-.67.97-.98 1.56-1.56c.68-.69 1.5-1.03 2.47-1.03.97 0 1.8.34 2.48 1.02l1.3 1.32a3.48 3.48 0 0 1 1 2.48c0 .58-.11 1.11-.37 1.6l-.02.02v.02l-.02.04c-.14.27-.35.54-.6.8L16.23 15l-.01.02-.01.02c-.44.42-.92.7-1.43.83a4.55 4.55 0 0 0 1.23-3.52L18 10.38c.18-.21.3-.42.35-.65a2.03 2.03 0 0 0-.01-.9 1.96 1.96 0 0 0-.36-.58l-1.3-1.3a1.49 1.49 0 0 0-1.06-.42c-.42 0-.77.14-1.06.4l-1.2 1.27-.8.8-1.16 1.15c-.08.08-.18.21-.29.4a1.66 1.66 0 0 0-.08 1.12l.02.03v.02l.06.14s.01.03.05.06l.06.13.02.02.01.02.01.02c.05.08.1.13.14.16l.47.5c0 .04-.02.09-.04.15l-.06.12-1.15 1.15-.1.08-.56-.56a2.3 2.3 0 0 0-.18-.19c-.02-.01-.02-.03-.02-.04l-.02-.02a.37.37 0 0 1-.1-.12c-.03-.03-.05-.04-.05-.06l-.1-.15-.02-.02-.02-.04-.08-.17v-.02a5.1 5.1 0 0 1-.28-.69 1.03 1.03 0 0 1-.04-.26c-.06-.23-.1-.46-.1-.7v.01z" fill="#A8A8A8" fill-rule="evenodd"></path></svg></span></button></div></div></div><div class="ib o ao"></div></div><div class="ck ic"><div><div aria-hidden="false" class="ci"></div></div></div></div></div><div class="id ie if j i d"><div class="fj l"></div><div class="ig l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on twitter" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M20 5.34c-.67.41-1.4.7-2.18.87a3.45 3.45 0 0 0-5.02-.1 3.49 3.49 0 0 0-1.02 2.47c0 .28.03.54.07.8a9.91 9.91 0 0 1-7.17-3.66 3.9 3.9 0 0 0-.5 1.74 3.6 3.6 0 0 0 1.56 2.92 3.36 3.36 0 0 1-1.55-.44V10c0 1.67 1.2 3.08 2.8 3.42-.3.06-.6.1-.94.12l-.62-.06a3.5 3.5 0 0 0 3.24 2.43 7.34 7.34 0 0 1-4.36 1.49l-.81-.05a9.96 9.96 0 0 0 5.36 1.56c6.4 0 9.91-5.32 9.9-9.9v-.5c.69-.49 1.28-1.1 1.74-1.81-.63.3-1.3.48-2 .56A3.33 3.33 0 0 0 20 5.33" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="ig l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on facebook" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 12.04c0-4.3-3.47-7.79-7.75-7.79a7.77 7.77 0 0 0-5.9 12.84 7.77 7.77 0 0 0 4.69 2.63v-5.49h-1.9v-2.2h1.9v-1.62c0-1.88 1.14-2.9 2.8-2.9.8 0 1.49.06 1.69.08v1.97h-1.15c-.91 0-1.1.43-1.1 1.07v1.4h2.17l-.28 2.2h-1.88v5.52a7.77 7.77 0 0 0 6.7-7.71" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="ig l fr"><div><div aria-hidden="false" class="ci"><button aria-label="Share on linkedin" class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path d="M19.75 5.39v13.22a1.14 1.14 0 0 1-1.14 1.14H5.39a1.14 1.14 0 0 1-1.14-1.14V5.39a1.14 1.14 0 0 1 1.14-1.14h13.22a1.14 1.14 0 0 1 1.14 1.14zM8.81 10.18H6.53v7.3H8.8v-7.3zM9 7.67a1.31 1.31 0 0 0-1.3-1.32h-.04a1.32 1.32 0 0 0 0 2.64A1.31 1.31 0 0 0 9 7.71v-.04zm8.46 5.37c0-2.2-1.4-3.05-2.78-3.05a2.6 2.6 0 0 0-2.3 1.18h-.07v-1h-2.14v7.3h2.28V13.6a1.51 1.51 0 0 1 1.36-1.63h.09c.72 0 1.26.45 1.26 1.6v3.91h2.28l.02-4.43z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="l fr"><div><div aria-hidden="false" class="ci"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg fill="none" height="24" viewbox="0 0 24 24" width="24"><path clip-rule="evenodd" d="M3.57 14.67c0-.57.13-1.11.38-1.6l.02-.02v-.02l.02-.02c0-.02 0-.02.02-.02.12-.26.3-.52.57-.8L7.78 9v-.02l.01-.02c.44-.41.91-.7 1.44-.85a4.87 4.87 0 0 0-1.19 2.36A5.04 5.04 0 0 0 8 11.6L6.04 13.6c-.19.19-.32.4-.38.65a2 2 0 0 0 0 .9c.08.2.2.4.38.57l1.29 1.31c.27.28.62.42 1.03.42.42 0 .78-.14 1.06-.42l1.23-1.25.79-.78 1.15-1.16c.08-.09.19-.22.28-.4.1-.2.15-.42.15-.67 0-.16-.02-.3-.06-.45l-.02-.02v-.02l-.07-.14s0-.03-.04-.06l-.06-.13-.02-.02c0-.02 0-.03-.02-.05a.6.6 0 0 0-.14-.16l-.48-.5c0-.04.02-.1.04-.15l.06-.12 1.17-1.14.09-.09.56.57c.02.04.08.1.16.18l.05.04.03.06.04.05.03.04.04.06.1.14.02.02c0 .02.01.03.03.04l.1.2v.02c.1.16.2.38.3.68a1 1 0 0 1 .04.25 3.2 3.2 0 0 1 .02 1.33 3.49 3.49 0 0 1-.95 1.87l-.66.67-.97.97-1.56 1.57a3.4 3.4 0 0 1-2.47 1.02c-.97 0-1.8-.34-2.49-1.03l-1.3-1.3a3.55 3.55 0 0 1-1-2.51v-.01h-.02v.02zm5.39-3.43c0-.19.02-.4.07-.63.13-.74.44-1.37.95-1.87l.66-.67.97-.98 1.56-1.56c.68-.69 1.5-1.03 2.47-1.03.97 0 1.8.34 2.48 1.02l1.3 1.32a3.48 3.48 0 0 1 1 2.48c0 .58-.11 1.11-.37 1.6l-.02.02v.02l-.02.04c-.14.27-.35.54-.6.8L16.23 15l-.01.02-.01.02c-.44.42-.92.7-1.43.83a4.55 4.55 0 0 0 1.23-3.52L18 10.38c.18-.21.3-.42.35-.65a2.03 2.03 0 0 0-.01-.9 1.96 1.96 0 0 0-.36-.58l-1.3-1.3a1.49 1.49 0 0 0-1.06-.42c-.42 0-.77.14-1.06.4l-1.2 1.27-.8.8-1.16 1.15c-.08.08-.18.21-.29.4a1.66 1.66 0 0 0-.08 1.12l.02.03v.02l.06.14s.01.03.05.06l.06.13.02.02.01.02.01.02c.05.08.1.13.14.16l.47.5c0 .04-.02.09-.04.15l-.06.12-1.15 1.15-.1.08-.56-.56a2.3 2.3 0 0 0-.18-.19c-.02-.01-.02-.03-.02-.04l-.02-.02a.37.37 0 0 1-.1-.12c-.03-.03-.05-.04-.05-.06l-.1-.15-.02-.02-.02-.04-.08-.17v-.02a5.1 5.1 0 0 1-.28-.69 1.03 1.03 0 0 1-.04-.26c-.06-.23-.1-.46-.1-.7v.01z" fill="#A8A8A8" fill-rule="evenodd"></path></svg></span></button></div></div></div></div></header><span class="l"></span><section><div><div class="fo as in io ip iq"></div><div class="ir is it iu iv"><div class=""><h1 class="pw-post-title iw ix iy bm iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ga" id="a902">Lessons From Deploying Deep Learning To Production</h1></div><div class=""><h2 class="pw-subtitle-paragraph jv ix iy bm b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km cn" id="decc">Sharing lessons so you don’t learn them the hard way</h2></div><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="1f27">When I started my first job out of college, I thought I knew a fair amount about machine learning. I had done two internships at Pinterest and Khan Academy building machine learning systems. I spent my last year at Berkeley doing research in deep learning for computer vision and working on Caffe, one of the first popular deep learning libraries. After I graduated, I joined a small startup called Cruise that was building self-driving cars. Now I’m at Aquarium, where I get to help a multitude of companies deploying deep learning models to solve important problems for society.</p><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="dcad">Over the years, I got the chance to build out pretty cool deep learning and computer vision stacks. There are a lot more people using deep learning in production applications nowadays compared to when I was doing research at Berkeley, but many problems that they face are the same ones I grappled with in 2016 at Cruise. I’ve learned a lot of lessons about doing deep learning in production, and I’d like to share some of those lessons with you so you don’t have to learn them the hard way.</p><h1 class="lj lk iy bm ll lm ln lo lp lq lr ls lt ke lu kf lv kh lw ki lx kk ly kl lz ma ga" id="9ba7"><strong class="ba">A Story</strong></h1><figure class="mc md me mf gx mg gl gm paragraph-image"><div class="mh mi do mj ce mk" role="button" tabindex="0"><div class="gl gm mb"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/0*rhS00VVlVaG41QY0 640w, https://miro.medium.com/max/720/0*rhS00VVlVaG41QY0 720w, https://miro.medium.com/max/750/0*rhS00VVlVaG41QY0 750w, https://miro.medium.com/max/786/0*rhS00VVlVaG41QY0 786w, https://miro.medium.com/max/828/0*rhS00VVlVaG41QY0 828w, https://miro.medium.com/max/1100/0*rhS00VVlVaG41QY0 1100w, https://miro.medium.com/max/1400/0*rhS00VVlVaG41QY0 1400w"/><img alt="" class="ce ml mm c" height="525" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="mn bl gn gl gm mo mp bm b bn bo cn">The car as it looked when we were developing the first ML models. The new ones are much nicer. (Image by author)</figcaption></figure><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="1893">To start off, let me talk about the first ever ML model deployed onto the car at Cruise. As we developed the model, the workflow felt a lot like what I was used to from my research days. We trained open source models on open source data, integrated them into our production software stack, and deployed them onto the car. After a few weeks of work, we merged the final PR to turn on the model to run on the car. “Mission accomplished!” I thought, and then we moved on to putting out the next fire. Little did I know that the real work had only just begun.</p><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="5310">As the model ran in production, our QA team started to notice problems with its performance. But we had other models to set up and fires to fight, so we didn’t try to immediately address the issues. 3 months later, when we looked into them, we discovered that the training and validation scripts had all broken due to changes in the codebase since the first time we deployed!</p><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="8c88">After a week of fixing that, we looked at the failures over the past few months and realized that a lot of the problems we observed in the model’s production runs could not be easily solved by modifying the model code, and that we needed to go collect and label new data from our vehicles instead of relying on open source data. This meant that we needed to set up a labeling process with all of the tools, operations, and infrastructure that this process would entail.</p><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="afd7">Another 3 months later, we were able to ship a new model that was trained on randomly selected data that we had collected from our vehicles and then labeled with our own tools. But as we started solving the easy problems, it got harder and harder to improve the model, and we had to become a lot smarter about what changes were likely to yield results. Around 90% of the problems were solved with careful data curation of difficult or rare scenarios instead of deep model architecture changes or hyperparameter tuning. For example, we discovered that the model had poor performance on rainy days (rare in San Francisco) so we labeled more data from rainy days, retrained the model on the new data, and the model performance improved. Similarly, we discovered that the model had poor performance on green cones (rare compared to orange cones) so we collected data of green cones, went through the same process, and model performance improved. We needed to set up a process where we could quickly identify and fix these types of problems.</p><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="445c">It took only a few weeks to hack together the first version of the model. Then another 6 months to ship a new and improved version of the model. And as we worked more on some of the pieces (better labeling infrastructure, cloud data processing, training infrastructure, deployment monitoring) we were able to retrain and redeploy models about every month to every week. As we set up more model pipelines from scratch and worked on improving them, we began to see some common themes. Applying our learnings to the new pipelines, it became easier to ship better models faster and with less effort.</p><h1 class="lj lk iy bm ll lm ln lo lp lq lr ls lt ke lu kf lv kh lw ki lx kk ly kl lz ma ga" id="c791"><strong class="ba">Always Be Iterating</strong></h1><div class="mc md me mf gx o hc"><figure class="mq mg mr ms mt mu mv paragraph-image"><div class="mh mi do mj ce mk" role="button" tabindex="0"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 356px" srcset="https://miro.medium.com/max/640/0*s5QPI-lvAoyhmet9 640w, https://miro.medium.com/max/720/0*s5QPI-lvAoyhmet9 720w, https://miro.medium.com/max/750/0*s5QPI-lvAoyhmet9 750w, https://miro.medium.com/max/786/0*s5QPI-lvAoyhmet9 786w, https://miro.medium.com/max/828/0*s5QPI-lvAoyhmet9 828w, https://miro.medium.com/max/1100/0*s5QPI-lvAoyhmet9 1100w, https://miro.medium.com/max/712/0*s5QPI-lvAoyhmet9 712w"/><img alt="" class="ce ml mm c" height="894" loading="eager" role="presentation" width="356"/></picture></div></figure><figure class="mq mg mw ms mt mu mv paragraph-image"><div class="mh mi do mj ce mk" role="button" tabindex="0"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 298px" srcset="https://miro.medium.com/max/640/0*awcrhnTa3NTkdZHx 640w, https://miro.medium.com/max/720/0*awcrhnTa3NTkdZHx 720w, https://miro.medium.com/max/750/0*awcrhnTa3NTkdZHx 750w, https://miro.medium.com/max/786/0*awcrhnTa3NTkdZHx 786w, https://miro.medium.com/max/828/0*awcrhnTa3NTkdZHx 828w, https://miro.medium.com/max/1100/0*awcrhnTa3NTkdZHx 1100w, https://miro.medium.com/max/596/0*awcrhnTa3NTkdZHx 596w"/><img alt="" class="ce ml mm c" height="1067" loading="eager" role="presentation" width="298"/></picture></div></figure><figure class="mq mg mx ms mt mu mv paragraph-image"><div class="mh mi do mj ce mk" role="button" tabindex="0"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 348px" srcset="https://miro.medium.com/max/640/0*A2xpZtRHpRm7fisO 640w, https://miro.medium.com/max/720/0*A2xpZtRHpRm7fisO 720w, https://miro.medium.com/max/750/0*A2xpZtRHpRm7fisO 750w, https://miro.medium.com/max/786/0*A2xpZtRHpRm7fisO 786w, https://miro.medium.com/max/828/0*A2xpZtRHpRm7fisO 828w, https://miro.medium.com/max/1100/0*A2xpZtRHpRm7fisO 1100w, https://miro.medium.com/max/696/0*A2xpZtRHpRm7fisO 696w"/><img alt="" class="ce ml mm c" height="914" loading="eager" role="presentation" width="348"/></picture></div><figcaption class="mn bl gn gl gm mo mp bm b bn bo cn my do mz na">Many different deep learning teams in self driving have converged on a fairly similar iteration cycle for their model pipelines. From left to right: <a class="au nb" href="https://youtu.be/Q0nGo2-y0xY?t=1064" rel="noopener ugc nofollow" target="_blank">Waymo</a>, <a class="au nb" href="/cruise/cruise-continuous-learning-machine-30d60f4c691b" rel="noopener">Cruise</a>, and <a class="au nb" href="https://youtu.be/Ucp0TTmvqOE?t=7780" rel="noopener ugc nofollow" target="_blank">Tesla</a>.</figcaption></figure></div><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="014d">I used to think that machine learning was about the models. Actually, machine learning in production is about pipelines. One of the best predictors of success is the ability to effectively iterate on your model pipeline. That doesn’t just mean iterating quickly, but also iterating intelligently. The second part is crucial, otherwise you end up with a pipeline that produces bad models very quickly.</p><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="3bfd">Most traditional software is developed in an agile process that emphasizes quick iterations and delivery. This is because the requirements of the product are unknown and must be discovered through adaptation, so it’s better to ship an MVP quickly and iterate than to do exhaustive planning up-front with shaky assumptions.</p><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="2f46">Just as the requirements of traditional software are complex, the domain of data inputs that ML systems must handle is truly vast. Unlike normal software development, the quality of an ML model depends on its implementation in code and on the data that code trains on. This dependency on the data means that the ML model can “explore” the input domain through dataset construction / curation, allowing it to understand the requirements of the task and adapt to it over time without necessarily having to modify the code.</p><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="8e06">To take advantage of this property, machine learning needs a concept of continuous learning that emphasizes iteration on the data as well as the code. Machine learning teams have to:</p><ul class=""><li class="nc nd iy kp b kq kr kt ku kw ne la nf le ng li nh ni nj nk ga" id="db6d">Uncover problems in the data or model performance</li><li class="nc nd iy kp b kq nl kt nm kw nn la no le np li nh ni nj nk ga" id="0e69">Diagnose why the problems are happening</li><li class="nc nd iy kp b kq nl kt nm kw nn la no le np li nh ni nj nk ga" id="e36a">Change the data or the model code to solve these problems</li><li class="nc nd iy kp b kq nl kt nm kw nn la no le np li nh ni nj nk ga" id="1553">Validate that the model is getting better after retraining</li><li class="nc nd iy kp b kq nl kt nm kw nn la no le np li nh ni nj nk ga" id="4792">Deploy the new model and repeat</li></ul><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="ca69">Teams should try to go through this cycle at least every month. If you’re good, maybe every week.</p><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="8355">Massive companies can run through the model deployment cycle in less than a day, but it’s very difficult for most teams to build the infrastructure to do this quickly and automatically. Updating models any less frequently than this can lead to code rot (where the model pipeline breaks due to changes to the codebase) or data domain shifts (where the model in production cannot generalize to changes in the data over time).</p><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="7074">However, if done right, a team can get into a good cadence where they are deploying improved models to production on a regular schedule.</p><h1 class="lj lk iy bm ll lm ln lo lp lq lr ls lt ke lu kf lv kh lw ki lx kk ly kl lz ma ga" id="887e"><strong class="ba">Set Up A Feedback Loop</strong></h1><figure class="mc md me mf gx mg gl gm paragraph-image"><div class="mh mi do mj ce mk" role="button" tabindex="0"><div class="gl gm mb"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/0*_dtkQ3vH3Op6i_lG 640w, https://miro.medium.com/max/720/0*_dtkQ3vH3Op6i_lG 720w, https://miro.medium.com/max/750/0*_dtkQ3vH3Op6i_lG 750w, https://miro.medium.com/max/786/0*_dtkQ3vH3Op6i_lG 786w, https://miro.medium.com/max/828/0*_dtkQ3vH3Op6i_lG 828w, https://miro.medium.com/max/1100/0*_dtkQ3vH3Op6i_lG 1100w, https://miro.medium.com/max/1400/0*_dtkQ3vH3Op6i_lG 1400w"/><img alt="" class="ce ml mm c" height="478" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="mn bl gn gl gm mo mp bm b bn bo cn"><a class="au nb" href="https://proceedings.neurips.cc/paper/2017/file/2650d6089a6d640c5e85b2b88265dc2b-Paper.pdf" rel="noopener ugc nofollow" target="_blank">Calibrated model uncertainty is an enticing research area where a model can flag where it thinks it might be failing.</a></figcaption></figure><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="0dff">A key part of effective iteration on a model is to focus effort on solving the most impactful problems. To improve a model, you need to be able to know what is wrong with it and be able to triage the problems based on priority for the product / business. There are a lot of ways to set up a feedback loop, but it starts with discovery and triage of errors.</p><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="2611">Leverage domain-specific feedback loops. When available, these can be very powerful and efficient ways of getting model feedback. For example, forecasting tasks can get labeled data “for free” by training on historical data of what actually happened, allowing them to continually feed in large amounts of new data and fairly automatically adapt to new situations.</p><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="b492">Set up a workflow where a human can review the outputs of your model and flag when an error occurs. This is particularly appropriate when it’s easy for human review to catch mistakes across a lot of model inferences. The most common way this occurs is when customers notice mistakes in the model outputs and complain to the ML team. This is not to be underestimated, as this channel lets you directly incorporate customer feedback into the development cycle! A team can have humans double-check model outputs that a customer might miss: think of an operations person watching a robot sort packages on a conveyor belt and clicking a button whenever they notice an error occurring.</p><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="785b">When the models run at too high a frequency for humans to check, consider setting up automated double-checking. This is particularly useful when it’s easy to write “sanity checks” against the model outputs. For example, flagging whenever a lidar object detector and 2D image object detector disagree on a certain object, or when a frame-to-frame detector disagrees with a temporal tracking system. When it works, it provides a lot of helpful feedback on where failure cases occur. When it doesn’t work, it simply exposes errors in your checking system or misses out on situations where all the systems made an error, which is pretty low risk high reward.</p><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="7aa2">The most general (but difficult) solution is to analyze model uncertainty about the data it is running on. A naive example is to look at examples where the model produced low confidence outputs in production. This can surface places where the model is truly uncertain, but it’s not 100% precise. Sometimes the model can be confidently wrong. Sometimes the model is uncertain due to lack of information available to make a good inference (for example, noisy input data that a human would struggle to make sense of). There are models that can solve these problems, but this is an active research area [1].</p><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="add2">Lastly, one can utilize feedback from the model’s feedback on the training set. For example, examining the model’s disagreement with its training / validation dataset (i.e. high loss examples) surfaces high-confidence failures or labeling errors. Analysis of neural network embeddings can provide a way to understand patterns of failure modes in the training / validation dataset and find differences in the distribution of the raw data between the training and production datasets.</p><h1 class="lj lk iy bm ll lm ln lo lp lq lr ls lt ke lu kf lv kh lw ki lx kk ly kl lz ma ga" id="3eef"><strong class="ba">Automate and Delegate</strong></h1><figure class="mc md me mf gx mg gl gm paragraph-image"><div class="mh mi do mj ce mk" role="button" tabindex="0"><div class="gl gm nq"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/0*sh-hJq4SN6HjTBKn 640w, https://miro.medium.com/max/720/0*sh-hJq4SN6HjTBKn 720w, https://miro.medium.com/max/750/0*sh-hJq4SN6HjTBKn 750w, https://miro.medium.com/max/786/0*sh-hJq4SN6HjTBKn 786w, https://miro.medium.com/max/828/0*sh-hJq4SN6HjTBKn 828w, https://miro.medium.com/max/1100/0*sh-hJq4SN6HjTBKn 1100w, https://miro.medium.com/max/1400/0*sh-hJq4SN6HjTBKn 1400w"/><img alt="" class="ce ml mm c" height="129" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="mn bl gn gl gm mo mp bm b bn bo cn">Most human time is pretty easy to remove from a typical retrain cycle. Even if that comes at the cost of less efficient machine time, it removes a lot of manual pain and anguish. (Image by author)</figcaption></figure><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="0a9b">A big part of iterating faster is reducing the amount of effort needed to do a single cycle of iteration. However, there’s always ways to make things easier, so one must prioritize what to improve. I like to think about effort in two ways: clock time and human time.</p><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="5f94">Clock time refers to time needed to run certain computational tasks like ETL of data, training models, running inference, calculating metrics, etc. Human time refers to time where a human must actively intervene to run through the pipeline, like manually inspecting results, running commands, or triggering scripts in the middle of the pipeline.</p><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="c48d">In a production context, human time is a far more limited resource. Intermittent usage of human time also imposes significant switching costs and is inconvenient for the user. Generally, it’s much more important to automate away human time, especially when the time required comes from a skilled ML engineer. For example, it’s extremely common but wasteful to have multiple scripts that must be manually run in sequence with some manual moving of files between steps. Some back of the napkin math: if an ML engineer costs $90 an hour and wastes even 2 hours per week to manually run scripts, that adds up to $9360 per year per person! Combining multiple scripts with human interrupts into a single fully-automatic script makes it much faster and easier to run through a single cycle of the model pipeline, saves a lot of money, and makes your ML engineer much less cranky.</p><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="fbce">In contrast, clock time generally needs to be “reasonable” (e.g.. can be completed overnight) to be acceptable. The exception is if ML engineers are running a huge number of experiments or if there are extreme cost / scaling constraints. This is because clock time is generally proportional to data scale and model complexity. There’s a significant reduction in clock time when moving from local processing to distributed cloud processing. After that, horizontal scaling in the cloud tends to solve most problems for most teams until getting to mega-scale.</p><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="5f06">Unfortunately, it can be impossible to completely automate certain tasks. Almost all production machine learning applications are supervised learning tasks, and most rely on some amount of human interaction to tell the model what it should do. In some domains, human interaction comes for free (for example, with social media recommendation use cases or other applications with a high volume of direct user feedback). In others, human time is more limited or expensive, such as highly trained radiologists “labeling” CT scans for training data.</p><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="ab23">Either way, it is important to minimize the amount of time (and associated costs) needed from humans to improve the model. While teams that are early on in the process might rely on an ML engineer to curate the dataset, it’s often more economical (or in the radiologist case, necessary) to have an operations user or domain expert without ML knowledge take on the heavy lifting of data curation. At that point, it becomes important to set up an operational process with good software tooling to label, quality check, improve, and version control the dataset.</p><h1 class="lj lk iy bm ll lm ln lo lp lq lr ls lt ke lu kf lv kh lw ki lx kk ly kl lz ma ga" id="d391"><strong class="ba">When It Works: ML Engineering At The Gym</strong></h1><figure class="mc md me mf gx mg gl gm paragraph-image"><div class="mh mi do mj ce mk" role="button" tabindex="0"><div class="gl gm mb"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/max/640/0*Nb9LjVRAx9pYE1fA 640w, https://miro.medium.com/max/720/0*Nb9LjVRAx9pYE1fA 720w, https://miro.medium.com/max/750/0*Nb9LjVRAx9pYE1fA 750w, https://miro.medium.com/max/786/0*Nb9LjVRAx9pYE1fA 786w, https://miro.medium.com/max/828/0*Nb9LjVRAx9pYE1fA 828w, https://miro.medium.com/max/1100/0*Nb9LjVRAx9pYE1fA 1100w, https://miro.medium.com/max/1400/0*Nb9LjVRAx9pYE1fA 1400w"/><img alt="" class="ce ml mm c" height="467" loading="lazy" role="presentation" width="700"/></picture></div></div><figcaption class="mn bl gn gl gm mo mp bm b bn bo cn"><a class="au nb" href="https://www.pexels.com/photo/person-holding-barbell-841130/" rel="noopener ugc nofollow" target="_blank">ML engineer lifts weights as their model learns weights</a></figcaption></figure><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="ace5">It can take a lot of time and effort to build adequate tooling to support a new domain or a new user group, but when done well, the results are well worth it! At Cruise, one engineer I worked with was particularly clever (some would say lazy).</p><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="4048">This engineer set up an iteration cycle where a combination of operations feedback and metadata queries would sample data to label from places where the model had poor performance. An offshore operations team would then label the data and add it to a new version of the training dataset. The engineer then set up infrastructure that allowed them to run a single script on their computer and kick off a series of cloud jobs that automatically retrained and validated a simple model on the newly added data.</p><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="9ea0">Every week, they ran the retrain script. Then they went to the gym while the model trained and validated itself. After a few hours of gym and dinner, they would return to examine the results. Invariably, the new and improved data would lead to model improvements. After a quick double-check to make sure everything made sense, they then shipped the new model to production and the car’s driving performance would improve. They then spent the rest of the week working on improving the infrastructure, experimenting with new model architectures, and building new model pipelines. Not only did this engineer get their promotion at the end of the quarter, they were in great shape!</p><h1 class="lj lk iy bm ll lm ln lo lp lq lr ls lt ke lu kf lv kh lw ki lx kk ly kl lz ma ga" id="31f9"><strong class="ba">The Takeaway</strong></h1><p class="pw-post-body-paragraph kn ko iy kp b kq nr jz ks kt ns kc kv kw nt ky kz la nu lc ld le nv lg lh li ir ga" id="01a8">So to recap: in research and prototyping stages, the focus is on building and shipping a model. But as a system moves into production, the name of the game is in building a system that is able to regularly ship improved models with minimal effort. The better you get at this, the more models you can build!</p><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="9fe0">To that end, it pays to focus on:</p><ul class=""><li class="nc nd iy kp b kq kr kt ku kw ne la nf le ng li nh ni nj nk ga" id="8da1">Running through the model pipeline on a regular cadence and focusing on shipping models that are better than before. Get a new and improved model into production every week or less!</li><li class="nc nd iy kp b kq nl kt nm kw nn la no le np li nh ni nj nk ga" id="70c0">Setting up a good feedback loop from the model outputs back to the development process. Figure out what examples the model does poorly on and add more examples to your training dataset.</li><li class="nc nd iy kp b kq nl kt nm kw nn la no le np li nh ni nj nk ga" id="eacb">Automating tasks in the pipeline that are particularly burdensome and building a team structure that allows your team members to focus on their areas of expertise. Tesla’s Andrej Karpathy calls the ideal end state “<a class="au nb" href="https://www.braincreators.com/brainpower/insights/teslas-data-engine-and-what-we-should-all-learn-from-it" rel="noopener ugc nofollow" target="_blank">Operation Vacation</a>.” I say, set up a workflow where you can send your ML engineers to the gym and let your ML pipeline do the heavy lifting!</li></ul><h1 class="lj lk iy bm ll lm ln lo lp lq lr ls lt ke lu kf lv kh lw ki lx kk ly kl lz ma ga" id="32a4">Why I’m Working On Aquarium</h1><p class="pw-post-body-paragraph kn ko iy kp b kq nr jz ks kt ns kc kv kw nt ky kz la nu lc ld le nv lg lh li ir ga" id="18bd">The reality is that it’s not easy to set up a good machine learning pipeline, both in terms of building the necessary infrastructure and setting up a good operational process to effectively iterate.</p><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="4a47">There’s a lot of pieces to the puzzle (distributed training, production monitoring, etc.) that a team must either build in-house or stitch together paid / open-source tooling to solve. I cofounded a company called Aquarium that tackles a piece of this problem: our product helps teams figure out what’s wrong with their data + models, get the right data labeled to fix these problems, and validate that the problems are fixed as the model is retrained.</p><p class="pw-post-body-paragraph kn ko iy kp b kq kr jz ks kt ku kc kv kw kx ky kz la lb lc ld le lf lg lh li ir ga" id="a2d9">Check out <a class="au nb" href="https://www.aquariumlearning.com/" rel="noopener ugc nofollow" target="_blank">our site</a> if you want to learn more. If you’d like to try Aquarium out for your own dataset, <a class="au nb" href="https://www.aquariumlearning.com/sales" rel="noopener ugc nofollow" target="_blank">let us know</a>!</p><figure class="mc md me mf gx mg gl gm paragraph-image"><div class="gl gm nw"><picture><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 256px" srcset="https://miro.medium.com/max/640/0*En7vH_gidHzja7iS.png 640w, https://miro.medium.com/max/720/0*En7vH_gidHzja7iS.png 720w, https://miro.medium.com/max/750/0*En7vH_gidHzja7iS.png 750w, https://miro.medium.com/max/786/0*En7vH_gidHzja7iS.png 786w, https://miro.medium.com/max/828/0*En7vH_gidHzja7iS.png 828w, https://miro.medium.com/max/1100/0*En7vH_gidHzja7iS.png 1100w, https://miro.medium.com/max/512/0*En7vH_gidHzja7iS.png 512w"/><img alt="" class="ce ml mm c" height="256" loading="lazy" role="presentation" width="256"/></picture></div></figure></div></div></section></div></div></article>